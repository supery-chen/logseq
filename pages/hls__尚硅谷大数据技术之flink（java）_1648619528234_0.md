- 这里需要提到Flink中的几个关键组件：客户端（Client）、作业管理器（JobManager）和任务管理器（TaskManager）
  ls-type:: annotation
  hl-page:: 28
  id:: 62440a36-c97d-4cb0-939a-621b0e56e98b
- [:span]
  ls-type:: annotation
  hl-page:: 29
  id:: 62440a74-bd5d-41e4-b278-4d1f25aaba68
  hl-type:: area
  hl-stamp:: 1648626292381
- 会话模式比较适合于单个规模小、执行时间短的大量作业
  ls-type:: annotation
  hl-page:: 38
  id:: 62450ce5-4bd3-430d-ad09-3c77d87ceace
- 单作业模式在生产环境运行更加稳定，所以是实际应用的首选模式
  ls-type:: annotation
  hl-page:: 38
  id:: 62450cfa-2832-4b40-b6f9-7b46e358410e
- 我们需要为每一个提交的应用单独启动一个JobManager，也就是创建一个集群。这个JobManager只为执行这一个应用而存在，执行结束之后JobManager也就关闭了，这就是所谓的应用模式
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d13-0ed7-4469-962b-e908d22704a6
- 在会话模式下，集群的生命周期独立于集群上运行的任何作业的生命周期，并且提交的所有作业共享资源。而单作业模式为每个提交的作业创建一个集群，带来了更好的资源隔离，这时集群的生命周期与作业的生命周期绑定。最后，应用模式为每个应用程序创建一个会话集群，在JobManager上直接调用应用程序的main()方法
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d33-59e4-48c0-ad47-02c1bc2cd5f3
- YARN上部署的过程是：客户端把Flink应用提交给Yarn的ResourceManager, Yarn的ResourceManager会向Yarn的NodeManager申请容器。在这些容器上，Flink会部署JobManager和TaskManager的实例，从而启动集群。Flink会根据运行在JobManger上的作业所需要的Slot数量动态分配TaskManager资源。
  ls-type:: annotation
  hl-page:: 42
  id:: 62450dec-7154-4f5d-819e-fc4150cff13e
- [:span]
  ls-type:: annotation
  hl-page:: 49
  id:: 62451f28-540a-4c62-abfe-46958ef9aef6
  hl-type:: area
  hl-stamp:: 1648697128409
- Flink的运行时架构中，最重要的就是两大组件：作业管理器（JobManger）和任务管理器（TaskManager）。对于一个提交执行的作业，JobManager是真正意义上的“管理者”（Master），负责管理调度，所以在不考虑高可用的情况下只能有一个；而TaskManager是“工作者”（Worker、Slave），负责执行任务处理数据，所以可以有一个或多个。Flink的作业提交和任务处理时的系统如图4-1所示。
  ls-type:: annotation
  hl-page:: 48
  id:: 62451f57-78fd-4be4-ad93-a47a58f42523
- [:span]
  ls-type:: annotation
  hl-page:: 51
  id:: 62453fc2-a342-43cb-8e2c-678f7917fb1d
  hl-type:: area
  hl-stamp:: 1648705474055
- [:span]
  ls-type:: annotation
  hl-page:: 52
  id:: 62454063-0020-4aa4-b678-18e16e071e4f
  hl-type:: area
  hl-stamp:: 1648705635790
- [:span]
  ls-type:: annotation
  hl-page:: 53
  id:: 62454115-6eba-4154-ab1d-e057d767c4a2
  hl-type:: area
  hl-stamp:: 1648705813730
- [:span]
  ls-type:: annotation
  hl-page:: 54
  id:: 62454135-1954-4edb-99bf-2f6d9975f66e
  hl-type:: area
  hl-stamp:: 1648705845181
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 624541f2-189f-4995-a375-3ef37f35add8
  hl-type:: area
  hl-stamp:: 1648706034535
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 6245466b-87c3-47f2-b8e0-eb30d8b2cfa7
  hl-type:: area
  hl-stamp:: 1648707179638
- [:span]
  ls-type:: annotation
  hl-page:: 57
  id:: 62454701-8930-4021-934b-388c85a330e5
  hl-type:: area
  hl-stamp:: 1648707329143
- 一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。这样，包含并行子任务的数据流，就是并行数据流，它需要多个分区（stream  partition）来分配并行任务。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。如图4-8所示，当前数据流中有source、map、window、sink四个算子，除最后sink，其他算子的并行度都为2。整个程序包含了7个子任务，至少需要2个分区来并行执行。我们可以说，这段流处理程序的并行度就是2。
  ls-type:: annotation
  hl-page:: 57
  id:: 6245471b-13ef-4cfb-975d-69af821a09d0
- [:span]
  ls-type:: annotation
  hl-page:: 61
  id:: 62454a8d-db87-42a7-838d-611c206f0a5e
  hl-type:: area
  hl-stamp:: 1648708237078
- [:span]
  ls-type:: annotation
  hl-page:: 63
  id:: 62454e39-97d3-4303-a24a-a1467fc124fa
  hl-type:: area
  hl-stamp:: 1648709177499
- 我们可以通过集群的配置文件来设定TaskManager的slot数量：taskmanager.numberOfTaskSlots: 8通过调整slot的数量，我们就可以控制子任务之间的隔离级别。具体来说，如果一个TaskManager只有一个slot，那将意味着每个任务都会运行在独立的JVM中（当然，该JVM可能是通过一个特定的容器启动的）；而一个TaskManager设置多个slot则意味着多个子任务可以共享同一个JVM。它们的区别在于：前者任务之间完全独立运行，隔离级别更高、彼此间的影响可以降到最小；而后者在同一个JVM进程中运行的任务，将共享TCP连接和心跳消息，也可能共享数据集和数据结构，这就减少了每个任务的运行开销，在降低隔离级别的同时提升了性能。需要注意的是，slot目前仅仅用来隔离内存，不会涉及CPU的隔离。在具体应用时，可以将slot数量配置为机器的CPU核心数，尽量避免不同任务之间对CPU的竞争。这也是开发环境默认并行度设为机器CPU数量的原因。
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e59-5ef5-47ad-85b9-66b9677fa165
- [:span]
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e82-ff8f-4b89-b726-614cb95daff5
  hl-type:: area
  hl-stamp:: 1648709252945
- 默认情况下，Flink是允许子任务共享slot的
  ls-type:: annotation
  hl-page:: 65
  id:: 62454e91-b72e-43b4-86a2-5c5565148a9e
- 只要属于同一个作业，那么对于不同任务节点的并行子任务，就可以放到同一个slot上执行。所以对于第一个任务节点source→map，它的6个并行子任务必须分到不同的slot上（如果在同一slot就没法数据并行了），而第二个任务节点keyBy/window/apply的并行子任务却可以和第一个任务节点共享slot。于是最终结果就变成了：每个任务节点的并行子任务一字排开，占据不同的slot；而不同的任务节点的子任务可以共享slot。一个slot中，可以将程序处理的所有任务都放在这里执行，我们把它叫作保存了整个作业的运行管道（pipeline）。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454ee2-c050-42d0-a67a-8d1e48e7e94f
- 当我们将资源密集型和非密集型的任务同时放到一个slot中，它们就可以自行分配对资源占用的比例，从而保证最重的活平均分配给所有的TaskManager。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f17-cf32-4f0c-b7c4-06f09a36058b
- slot共享另一个好处就是允许我们保存完整的作业管道。这样一来，即使某个TaskManager出现故障宕机，其他节点也可以完全不受影响，作业的任务可以继续执行
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f2b-de44-4b9a-bef3-00b9580a1ecb
- 另外，同一个任务节点的并行子任务是不能共享slot的，所以允许slot共享之后，运行作业所需的slot数量正好就是作业中所有算子并行度的最大值。这样一来，我们考虑当前集群需要配置多少slot资源时，就不需要再去详细计算一个作业总共包含多少个并行子任务了，只看最大的并行度就够了
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f43-7104-418b-a2e3-2e593ce87043
- 当然，Flink默认是允许slot共享的，如果希望某个算子对应的任务完全独占一个slot，或者只有某一部分算子共享slot，我们也可以通过设置“slot共享组”（SlotSharingGroup）手动指定：.map(word -> Tuple2.of(word, 1L)).slotSharingGroup(“1”);这样，只有属于同一个slot共享组的子任务，才会开启slot共享；不同组之间的任务是完全隔离的，必须分配到不同的slot上。在这种场景下，总共需要的slot数量，就是各个slot共享组最大并行度的总和。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f5f-ecb2-4910-8248-aed5113b5b47
- [:span]
  ls-type:: annotation
  hl-page:: 69
  id:: 624551f0-6d44-4f88-b3d9-9d73db8febc9
  hl-type:: area
  hl-stamp:: 1648710128297
- StreamExecutionEnvironment                        env                        = StreamExecutionEnvironment.getExecutionEnvironment();
  ls-type:: annotation
  hl-page:: 69
  id:: 6245531d-7ab5-43c2-8e46-cace6d0eb13c
- StreamExecutionEnvironment                     localEnv                     = StreamExecutionEnvironment.createLocalEnvironment();
  ls-type:: annotation
  hl-page:: 70
  id:: 62455327-4900-47c2-a95b-64c588a3069e
- StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment.createRemoteEnvironment("host", // JobManager主机名1234, // JobManager进程端口号"path/to/jarFile.jar"// 提交给JobManager的JAR包); 
  ls-type:: annotation
  hl-page:: 70
  id:: 62455333-4059-4d0a-a266-e4d36f31f389
- 在获取到程序执行环境后，我们还可以对执行环境进行灵活的设置。比如可以全局设置程序的并行度、禁用算子链，还可以定义程序的时间语义、配置容错机制。关于时间语义和容错机制，我们会在后续的章节介绍。
  ls-type:: annotation
  hl-page:: 70
  id:: 6245533d-b444-4af3-855e-91035b9a28e8
- bin/flink run -Dexecution.runtime-mode=BATCH
  ls-type:: annotation
  hl-page:: 71
  id:: 624553b8-d0e6-46c6-908f-3c6be96c2c9f
- [:span]
  ls-type:: annotation
  hl-page:: 72
  id:: 6245550b-ea82-43bc-ab73-c4b9d079dd19
  hl-type:: area
  hl-stamp:: 1648710923832
- [:span]
  ls-type:: annotation
  hl-page:: 82
  id:: 62466b57-e09a-407f-bdf8-4e7212545c6e
  hl-type:: area
  hl-stamp:: 1648782167373
- “富函数类”也是DataStream  API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。既然“富”，那么它一定会比常规的函数类提供更多、更丰富的功能。与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。
  ls-type:: annotation
  hl-page:: 96
  id:: 6246c794-102a-411c-8d96-1a780b226178
- [:span]
  ls-type:: annotation
  hl-page:: 106
  id:: 624d0a28-e019-4df0-b32c-11d000f59cf8
  hl-type:: area
  hl-stamp:: 1649216040884
- [:span]
  ls-type:: annotation
  hl-page:: 107
  id:: 624d0aa0-3e59-4af2-87e7-97cfae105126
  hl-type:: area
  hl-stamp:: 1649216160184
- Flink为此专门提供了一个流式文件系统的连接器：StreamingFileSink，它继承自抽象类RichSinkFunction，而且集成了Flink的检查点（checkpoint）机制，用来保证精确一次（exactly once）的一致性语义
  ls-type:: annotation
  hl-page:: 108
  id:: 624d5897-727a-4259-ba83-8dfcd325e250
- StreamingFileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded，比如Parquet）格式。这两种不同的方式都有各自的构建器（builder），调用方法也非常简单，可以直接调用StreamingFileSink的静态方法
  ls-type:: annotation
  hl-page:: 108
  id:: 624d58b3-f284-494c-b4db-60cdbbf1b3bf
- Flink官方为Kafka提供了Source和Sink的连接器，我们可以用它方便地从Kafka读写数据。如果仅仅是支持读写，那还说明不了Kafka和Flink关系的亲密；真正让它们密不可分的是，Flink与Kafka的连接器提供了端到端的精确一次（exactlyonce）语义保证，这在实际项目中是最高级别的一致性保证。关于这部分内容，我们会在后续章节做更详细的讲解
  ls-type:: annotation
  hl-page:: 110
  id:: 624d5a84-e517-4adc-82bd-457353787338
- Flink没有直接提供官方的Redis连接器，不过Bahir项目还是担任了合格的辅助角色，为我们提供了Flink-Redis的连接工具。但版本升级略显滞后，目前连接器版本为1.0，支持的Scala版本最新到2.11。由于我们的测试不涉及到Scala的相关版本变化，所以并不影响使用。在实际项目应用中，应该以匹配的组件版本运行
  ls-type:: annotation
  hl-page:: 111
  id:: 624d5dd4-ef84-4514-a23e-b3ffdff8cac0
- ElasticSearch是一个分布式的开源搜索和分析引擎，适用于所有类型的数据。ElasticSearch有着简洁的REST风格的API，以良好的分布式特性、速度和可扩展性而闻名，在大数据领域应用非常广泛。Flink为ElasticSearch专门提供了官方的Sink 连接器，Flink1.13支持当前最新版本的ElasticSearch
  ls-type:: annotation
  hl-page:: 113
  id:: 624d64b8-ea6f-4870-a0b3-edacc8bbdc83
- 关系型数据库有着非常好的结构化数据设计、方便的SQL查询，是很多企业中业务数据存储的主要形式。MySQL就是其中的典型代表。尽管在大数据处理中直接与MySQL交互的场景不多，但最终处理的计算结果是要给外部应用消费使用的，而外部应用读取的数据存储往往就是MySQL。所以我们也需要知道如何将数据输出到MySQL这样的传统数据库
  ls-type:: annotation
  hl-page:: 116
  id:: 624d64f5-9a95-43e3-80a3-e8dec01baee7
- 与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的.addSink()方法就可以自定义写入任何外部存储
  ls-type:: annotation
  hl-page:: 118
  id:: 624d6516-35c7-44f1-90f2-f292732b462b
- 在实现SinkFunction的时候，需要重写的一个关键方法invoke()，在这个方法中我们就可以实现将流里的数据发送出去的逻辑
  ls-type:: annotation
  hl-page:: 118
  id:: 624d6528-9cff-4418-bfb0-3644bff5f1a3
- 在流数据处理应用中，一个很重要、也很常见的操作就是窗口计算。所谓的“窗口”，一般就是划定的一段时间范围，也就是“时间窗”；对在这范围内的数据进行处理，就是所谓的窗口计算。所以窗口和时间往往是分不开的。接下来我们就深入了解一下Flink中的时间语义和窗口的应用
  ls-type:: annotation
  hl-page:: 120
  id:: 624d73cd-f0f4-4503-8c5b-a249320e88a2
- [:span]
  ls-type:: annotation
  hl-page:: 121
  id:: 624d73e6-ad9f-4d11-bcb7-dec87e9b12b7
  hl-type:: area
  hl-stamp:: 1649243110616
- 如图6-1所示，在事件发生之后，生成的数据被收集起来，首先进入分布式消息队列，然后被Flink系统中的Source算子读取消费，进而向下游的转换算子（窗口算子）传递，最终由窗口算子进行计算处理
  ls-type:: annotation
  hl-page:: 121
  id:: 624d7450-47f1-4794-b90b-7a420f938162
- 处理时间的概念非常简单，就是指执行处理操作的机器的系统时间
  ls-type:: annotation
  hl-page:: 122
  id:: 624d747f-09b4-467a-9960-0f4471a71d76
- 事件时间，是指每个事件在对应的设备上发生的时间，也就是数据生成的时间
  ls-type:: annotation
  hl-page:: 122
  id:: 624d7486-7d16-4c11-8bf5-36eec0a20ca0
- 在实际应用中，事件时间语义会更为常见。一般情况下，业务日志数据中都会记录数据生成的时间戳（timestamp），它就可以作为事件时间的判断基础
  ls-type:: annotation
  hl-page:: 123
  id:: 624d752b-f7b6-40ec-956c-57fe3a40198c
- 事件时间语义是以一定延迟为代价，换来了处理结果的正确性。由于网络延迟一般只有毫秒级，所以即使是事件时间语义，同样可以完成低延迟实时流处理的任务
  ls-type:: annotation
  hl-page:: 124
  id:: 624d758e-ebea-4e88-9757-486fc6217c9f
- 另外，除了事件时间和处理时间，Flink还有一个“摄入时间”（Ingestion Time）的概念，它是指数据进入Flink数据流的时间，也就是Source算子读入数据的时间。摄入时间相当于是事件时间和处理时间的一个中和，它是把Source任务的处理时间，当作了数据的产生时间添加到数据里。这样一来，水位线（watermark）也就基于这个时间直接生成，不需要单独指定了。这种时间语义可以保证比较好的正确性，同时又不会引入太大的延迟。它的具体行为跟事件时间非常像，可以当作特殊的事件时间来处理。在Flink中，由于处理时间比较简单，早期版本默认的时间语义是处理时间；而考虑到事件时间在实际应用中更为广泛，从1.12版本开始，Flink已经将事件时间作为了默认的时间语义。
  ls-type:: annotation
  hl-page:: 124
  id:: 624d75b1-badc-4aaf-8841-2cf3c0567484
- [:span]
  ls-type:: annotation
  hl-page:: 126
  id:: 624d75ec-cd06-4784-a920-40e3e39611d1
  hl-type:: area
  hl-stamp:: 1649243628159
- 所以我们应该把时钟也以数据的形式传递出去，告诉下游任务当前时间的进展；而且这个时钟的传递不会因为窗口聚合之类的运算而停滞。一种简单的想法是，在数据流中加入一个时钟标记，记录当前的事件时间；这个标记可以直接广播到下游，当下游任务收到这个标记，就可以更新自己的时钟了。由于类似于水流中用来做标志的记号，在Flink中，这种用来衡量事件时间（Event Time）进展的标记，就被称作“水位线”（Watermark）。具体实现上，水位线可以看作一条特殊的数据记录，它是插入到数据流中的一个标记点，主要内容就是一个时间戳，用来指示当前的事件时间。而它插入流中的位置，就应该是在某个数据到来之后；这样就可以从这个数据中提取时间戳，作为当前水位线的时间戳了。
  ls-type:: annotation
  hl-page:: 127
  id:: 624d7695-7a05-4437-9d37-e5daced9ea8d
- [:span]
  ls-type:: annotation
  hl-page:: 127
  id:: 624d76a2-30ff-4449-ad1a-d17f74994e5f
  hl-type:: area
  hl-stamp:: 1649243810153
- 在理想状态下，数据应该按照它们生成的先后顺序、排好队进入流中；也就是说，它们处理的过程会保持原先的顺序不变，遵守先来后到的原则。这样的话我们从每个数据中提取时间戳，就可以保证总是从小到大增长的，从而插入的水位线也会不断增长、事件时钟不断向前推进
  ls-type:: annotation
  hl-page:: 127
  id:: 624d771d-b069-49ce-a5b8-daefa46b3118
- 实际应用中，如果当前数据量非常大，可能会有很多数据的时间戳是相同的，这时每来一条数据就提取时间戳、插入水位线就做了大量的无用功。而且即使时间戳不同，同时涌来的数据时间差会非常小（比如几毫秒），往往对处理计算也没什么影响。所以为了提高效率，一般会每隔一段时间生成一个水位线，这个水位线的时间戳，就是当前最新数据的时间戳，如图6-6所示。所以这时的水位线，其实就是有序流中的一个周期性出现的时间标记
  ls-type:: annotation
  hl-page:: 127
  id:: 624d7723-e7a3-4d42-a428-0e0506554434
- [:span]
  ls-type:: annotation
  hl-page:: 128
  id:: 624d7738-58d0-4497-8523-1da0b5853af2
  hl-type:: area
  hl-stamp:: 1649243960966
- 这里需要注意的是，水位线插入的“周期”，本身也是一个时间概念。在当前事件时间语义下，假如我们设定了每隔100ms生成一次水位线，那就是要等事件时钟推进100ms才能插入；但是事件时钟本身的进展，本身就是靠水位线来表示的——现在要插入一个水位线，可前提又是水位线要向前推进100ms，这就陷入了死循环。所以对于水位线的周期性生成，周期时间是指处理时间（系统时间），而不是事件时间
  ls-type:: annotation
  hl-page:: 128
  id:: 624d7741-e155-4d0c-90e5-af1da5cdbef8
- 有序流的处理非常简单，看起来水位线也并没有起到太大的作用。但这种情况只存在于理想状态下。我们知道在分布式系统中，数据在节点间传输，会因为网络传输延迟的不确定性，导致顺序发生改变，这就是所谓的“乱序数据”
  ls-type:: annotation
  hl-page:: 128
  id:: 624d7763-2dbe-4064-9d3f-61293225b7ea
- 这里所说的“乱序”（out-of-order），是指数据的先后顺序不一致，主要就是基于数据的产生时间而言的。如图6-7所示，一个7秒时产生的数据，生成时间自然要比9秒的数据早；但是经过数据缓存和传输之后，处理任务可能先收到了9秒的数据，之后7秒的数据才姗姗来迟。这时如果我们希望插入水位线，来指示当前的事件时间进展，又该怎么做呢
  ls-type:: annotation
  hl-page:: 128
  id:: 624d776b-b031-46fa-b4ec-7b3718ac549e
- [:span]
  ls-type:: annotation
  hl-page:: 128
  id:: 624d777a-befd-4f11-b81c-1c6020008671
  hl-type:: area
  hl-stamp:: 1649244026504
- 最直观的想法自然是跟之前一样，我们还是靠数据来驱动，每来一个数据就提取它的时间戳、插入一个水位线。不过现在的情况是数据乱序，所以有可能新的时间戳比之前的还小，如果直接将这个时间的水位线再插入，我们的“时钟”就回退了——水位线就代表了时钟，时光不能倒流，所以水位线的时间戳也不能减小
  ls-type:: annotation
  hl-page:: 128
  id:: 624d77a5-9d73-4204-800c-2ef0cbb3b99f
- 解决思路也很简单：我们插入新的水位线时，要先判断一下时间戳是否比之前的大，否则就不再生成新的水位线，如图6-8所示。也就是说，只有数据的时间戳比当前时钟大，才能推动时钟前进，这时才插入水位线
  ls-type:: annotation
  hl-page:: 128
  id:: 624d77ac-653e-4ebd-9da0-657b6aac48dc
- [:span]
  ls-type:: annotation
  hl-page:: 128
  id:: 624d77bc-da3e-4c0b-86ca-86db87ff8a47
  hl-type:: area
  hl-stamp:: 1649244092583
- 如果考虑到大量数据同时到来的处理效率，我们同样可以周期性地生成水位线。这时只需要保存一下之前所有数据中的最大时间戳，需要插入水位线时，就直接以它作为时间戳生成新的水位线
  ls-type:: annotation
  hl-page:: 129
  id:: 624d77cc-d526-4354-b5e1-0f4692ad5161
- [:span]
  ls-type:: annotation
  hl-page:: 129
  id:: 624d77d7-9e4b-4fa3-a20c-7f54cfa2dab3
  hl-type:: area
  hl-stamp:: 1649244119120
- 这样做尽管可以定义出一个事件时钟，却也会带来一个非常大的问题：我们无法正确处理“迟到”的数据
  ls-type:: annotation
  hl-page:: 129
  id:: 624d782d-730c-4fed-98dc-de769f768588
- 回到上面的例子，为了让窗口能够正确收集到迟到的数据，我们也可以等上2秒；也就是用当前已有数据的最大时间戳减去2秒，就是要插入的水位线的时间戳，如图6-10所示。这样的话，9秒的数据到来之后，事件时钟不会直接推进到9秒，而是进展到了7秒；必须等到11秒的数据到来之后，事件时钟才会进展到9秒，这时迟到数据也都已收集齐，0~9秒的窗口就可以正确计算结果了
  ls-type:: annotation
  hl-page:: 129
  id:: 624d787c-4f01-4921-b832-fa8862411c02
- [:span]
  ls-type:: annotation
  hl-page:: 130
  id:: 624d78a9-8735-4d43-bf6d-346f4ee6a988
  hl-type:: area
  hl-stamp:: 1649244329103
- 水位线是Flink流处理中保证结果正确性的核心机制，它往往会跟窗口一起配合，完成对乱序数据的正确处理
  ls-type:: annotation
  hl-page:: 131
  id:: 624d79e6-9e65-4aa9-9803-f604b7d61f5f
- 在Flink的DataStream  API中 ， 有 一 个 单 独 用 于 生 成 水 位 线 的 方法：.assignTimestampsAndWatermarks()，它主要用来为流中的数据分配时间戳，并生成水位线来指示事件时间
  ls-type:: annotation
  hl-page:: 132
  id:: 624d7ad7-aa62-4e31-8123-cdaa8f544abf
- 所有的上游并行任务就像围成木桶的一块块木板，它们中最短的那一块，决定了我们桶中的水位
  ls-type:: annotation
  hl-page:: 139
  id:: 624d86d4-800d-4c72-a550-e218a8fbf472
- [:span]
  ls-type:: annotation
  hl-page:: 139
  id:: 624d86e2-4ec4-4138-8b0e-76f997bd0677
  hl-type:: area
  hl-stamp:: 1649247970080
- Flink是一种流式计算引擎，主要是来处理无界数据流的，数据源源不断、无穷无尽。想要更加方便高效地处理无界流，一种方式就是将无限数据切割成有限的“数据块”进行处理，这就是所谓的“窗口”（Window）
  ls-type:: annotation
  hl-page:: 141
  id:: 624d8926-4f07-4842-bef4-85a8e3e77edb
- 在Flink中，窗口其实并不是一个“框”，流进来的数据被框住了就只能进这一个窗口。相比之下，我们应该把窗口理解成一个“桶”，如图6-15所示。在Flink中，窗口可以把流切割成有限大小的多个“存储桶”（bucket)；每个数据都会分发到对应的桶中，当到达窗口结束时间时，就对每个桶中收集的数据进行计算处理
  ls-type:: annotation
  hl-page:: 142
  id:: 624d893e-c501-4b9b-9519-f8305ac76d58
- [:span]
  ls-type:: annotation
  hl-page:: 142
  id:: 624d894c-f5c6-4dff-abe0-11347e5de48f
  hl-type:: area
  hl-stamp:: 1649248588599
- [:span]
  ls-type:: annotation
  hl-page:: 143
  id:: 624d8963-e525-484a-b9ce-8b2ca2d13bfc
  hl-type:: area
  hl-stamp:: 1649248611224
- 时间窗口（Time Window）
  ls-type:: annotation
  hl-page:: 144
  id:: 624d89c3-e8b3-42bf-9d43-f3303f46201d
- 计数窗口（Count Window）
  ls-type:: annotation
  hl-page:: 144
  id:: 624d89cc-a708-4f42-bf79-ba086afc0fd4
- 滚动窗口（Tumbling Windows）
  ls-type:: annotation
  hl-page:: 145
  id:: 624d89d5-8af4-47f9-b226-54dfaaef6ba3
- 滑动窗口（Sliding Windows）
  ls-type:: annotation
  hl-page:: 145
  id:: 624d89dd-a838-46bd-992e-cf0c2c902035
- 会话窗口（Session Windows）
  ls-type:: annotation
  hl-page:: 146
  id:: 624d89e8-74c3-4733-a361-05b2faf363de
- 全局窗口（Global Windows）
  ls-type:: annotation
  hl-page:: 147
  id:: 624d89f8-c4ae-4c95-ab8d-d33a24116fda
- [:span]
  ls-type:: annotation
  hl-page:: 148
  id:: 624d8cf7-33fa-489f-ba95-0201b2d026ee
  hl-type:: area
  hl-stamp:: 1649249527680
- [:span]
  ls-type:: annotation
  hl-page:: 149
  id:: 624d8d63-06b8-48a1-b56a-f76bc202904f
  hl-type:: area
  hl-stamp:: 1649249635320
- 窗口分配器（Window Assigners）
  ls-type:: annotation
  hl-page:: 149
  id:: 624d8f14-011b-4ccf-8b9d-44563aeca4db
- 窗口函数（Window Functions）
  ls-type:: annotation
  hl-page:: 152
  id:: 624d8f27-39b2-4e3b-8e81-3a82de5de67f
- [:span]
  ls-type:: annotation
  hl-page:: 152
  id:: 624d8f90-7c29-4740-ab8c-e6d989e54422
  hl-type:: area
  hl-stamp:: 1649250192559
- 增量聚合函数（incremental aggregation functions）
  ls-type:: annotation
  hl-page:: 153
  id:: 624d8f9f-0e0d-437d-9d91-2965fb9e9fe1
- 归约函数（ReduceFunction）
  ls-type:: annotation
  hl-page:: 153
  id:: 624d8fa9-5743-4779-952d-3c607b7219a9
- 聚合函数（AggregateFunction）
  ls-type:: annotation
  hl-page:: 155
  id:: 624d8fb1-7a06-4197-9240-7f339c3d4783
- 全窗口函数（full window functions）
  ls-type:: annotation
  hl-page:: 159
  id:: 624d8fc0-a0ff-40cb-bc20-b3d9ef6193e6
- 窗口函数（WindowFunction）
  ls-type:: annotation
  hl-page:: 159
  id:: 624d8fc8-f423-41d1-aa61-12dc4b2ec46e
- 处理窗口函数（ProcessWindowFunction）
  ls-type:: annotation
  hl-page:: 159
  id:: 624d8fcf-a24f-4d44-9e35-053e43ae793e
- 增量聚合和全窗口函数的结合使用
  ls-type:: annotation
  hl-page:: 162
  id:: 624e8adc-14d1-453b-856c-0f6f16d726c4
- 触发器（Trigger）
  ls-type:: annotation
  hl-page:: 169
  id:: 624e8b33-a97d-4167-a62f-4895d7ab1e8f
- 移除器（Evictor）
  ls-type:: annotation
  hl-page:: 173
  id:: 624e8fcb-e66d-4992-97e7-a504d42d9b43
- 允许延迟（Allowed Lateness）
  ls-type:: annotation
  hl-page:: 173
  id:: 624e8fda-742e-4ee0-a039-7b17e245f166
- 将迟到的数据放入侧输出流
  ls-type:: annotation
  hl-page:: 174
  id:: 624e9024-9c7e-49b4-a7dd-3a8c98f336e0
- [:span]
  ls-type:: annotation
  hl-page:: 183
  id:: 624f9fec-b367-4274-817e-1efe5ba2337f
  hl-type:: area
  hl-stamp:: 1649385452726
- 处理函数提供了一个“定时服务”（TimerService），我们可以通过它访问流中的事件（event）、时间戳（timestamp）、水位线（watermark），甚至可以注册“定时事件”。而且处理函数继承了AbstractRichFunction抽象类，所以拥有富函数类的所有特性，同样可以访问状态（state）和其他运行时信息。此外，处理函数还可以直接将数据输出到侧输出流（sideoutput）中。所以，处理函数是最为灵活的处理方法，可以实现各种自定义的业务逻辑；同时也是整个DataStreamAPI的底层基础
  ls-type:: annotation
  hl-page:: 184
  id:: 624fa609-e298-4607-9209-e15ad163052f
- 处理函数的使用与基本的转换操作类似，只需要直接基于DataStream调用.process()方法就可以了
  ls-type:: annotation
  hl-page:: 184
  id:: 624fa641-8b3e-416d-87a4-f854f536d145
- ProcessFunction解析
  ls-type:: annotation
  hl-page:: 185
  id:: 624fcaec-0a62-45dc-8ec7-6fcb18040cff
- 处理函数的分类
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcaf9-0fe7-4dbd-8d73-4d9d731f414a
- Flink提供了8个不同的处理函数
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb07-91b9-4613-b348-4f3549e1dee4
- ProcessFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb0f-820a-4cd0-b4ae-0ca7fdbb25ba
- KeyedProcessFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb15-d9f7-4612-9fc3-34e3cb8874dd
- ProcessWindowFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb1b-7a75-42d0-93a0-8dbf483345d9
- ProcessAllWindowFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb20-1768-44ca-8e12-b90ab03f6b1b
- CoProcessFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb29-5775-4665-97c8-2a3d59005df8
- ProcessJoinFunction
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcb2f-e54f-4ee5-a617-9b3de45dcdad
- BroadcastProcessFunction
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcb37-9ea0-4844-bc5b-892ba23266cc
- KeyedBroadcastProcessFunction
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcb3d-9372-443e-86f1-19c207a2240e
- 按键分区处理函数（KeyedProcessFunction）
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcdb1-350a-489a-9aec-9625f4472497
- [:span]
  ls-type:: annotation
  hl-page:: 210
  id:: 624ffdf8-0638-43ce-ae26-a770e8e19bed
  hl-type:: area
  hl-stamp:: 1649409528679
- [:span]
  ls-type:: annotation
  hl-page:: 214
  id:: 62500020-8592-4d21-bbec-c9acf4eaa582
  hl-type:: area
  hl-stamp:: 1649410080889
- [:span]
  ls-type:: annotation
  hl-page:: 214
  id:: 62500036-ceec-4550-9036-20eef640437d
  hl-type:: area
  hl-stamp:: 1649410102782
- 这里需要考虑一个问题。在事件时间语义下，水位线是时间的进度标志；不同的流中可能水位线的进展快慢完全不同，如果它们合并在一起，水位线又该以哪个为准呢？还以要考虑水位线的本质含义，是“之前的所有数据已经到齐了”；所以对于合流之后的水位线，也是要以最小的那个为准，这样才可以保证所有流都不会再传来之前的数据。换句话说，多流合并时处理的时效性是以最慢的那个流为准的。我们自然可以想到，这与之前介绍的并行任务水位线传递的规则是完全一致的；多条流的合并，某种意义上也可以看作是多个并行任务向同一个下游任务汇合的过程。
  ls-type:: annotation
  hl-page:: 214
  id:: 625002d5-6cc3-4cd5-8821-f2d1adeed9cd
- [:span]
  ls-type:: annotation
  hl-page:: 218
  id:: 6250ffc4-19c0-4baf-b90d-406b2ca215b7
  hl-type:: area
  hl-stamp:: 1649475524609
- ls-type:: annotation
  hl-page:: 225
  id:: 62511a66-6806-4ea1-9025-f80463bf4b46
  3. 广播连接流（BroadcastConnectedStream）关于两条流的连接，还有一种比较特殊的用法：DataStream调用.connect()方法时，传入的参数也可以不是一个DataStream，而是一个“广播流”（BroadcastStream），这时合并两条流得到的就变成了一个“广播连接流”（BroadcastConnectedStream）。这种连接方式往往用在需要动态定义某些规则或配置的场景。因为规则是实时变动的，所以我们可以用一个单独的流来获取规则数据；而这些规则或配置是对整个应用全局有效的，所以不能只把这数据传递给一个下游并行子任务处理，而是要“广播”（broadcast）给所有的并行子任务。而下游子任务收到广播出来的规则，会把它保存成一个状态，这就是所谓的“广播状态”（broadcast state）
- Flink中两条流的connect操作，就可以通过keyBy指定键进行分组后合并，实现了类似于SQL中的join操作；另外connect支持处理函数，可以使用自定义状态和TimerService灵活实现各种需求，其实已经能够处理双流合并的大多数场景
  ls-type:: annotation
  hl-page:: 226
  id:: 62511b22-c12d-4e2a-9375-e017ba80c9f0
- Flink为这种场景专门提供了一个窗口联结（window join）算子，可以定义时间窗口，并将两条流中共享一个公共键（key）的数据放在窗口中进行配对处理
  ls-type:: annotation
  hl-page:: 226
  id:: 62511b80-211a-469d-85a3-e080386f4a35
- 窗口联结在代码中的实现，首先需要调用DataStream的.join()方法来合并两条流，得到一个JoinedStreams；接着通过.where()和.equalTo()方法指定两条流中联结的key；然后通过.window()开窗口，并调用.apply()传入联结窗口函数进行处理计算。通用调用形式如下
  ls-type:: annotation
  hl-page:: 227
  id:: 62511bc7-3e07-4103-ae4c-8b9f6fb32aa9
- [:span]
  ls-type:: annotation
  hl-page:: 227
  id:: 62511bd4-6347-447f-8ec6-f9d3ead56c99
  hl-type:: area
  hl-stamp:: 1649482708757
- 间隔联结的思路就是针对一条流的每个数据，开辟出其时间戳前后的一段时间间隔，看这期间是否有来自另一条流的数据匹配
  ls-type:: annotation
  hl-page:: 231
  id:: 62512031-5555-40e9-a7bd-750bfbd254f8
- 间隔联结具体的定义方式是，我们给定两个时间点，分别叫作间隔的“上界”（upperBound）和“下界”（lowerBound）；于是对于一条流（不妨叫作A）中的任意一个数据元素a，就可以开辟一段时间间隔：[a.timestamp + lowerBound, a.timestamp + upperBound],即以a的时间戳为中心，下至下界点、上至上界点的一个闭区间：我们就把这段时间作为可以匹配另一条流数据的“窗口”范围。所以对于另一条流（不妨叫B）中的数据元素b，如果它的时间戳落在了这个区间范围内，a和b就可以成功配对，进而进行计算输出结果。所以匹配的条件为：a.timestamp + lowerBound <= b.timestamp <= a.timestamp + upperBound
  ls-type:: annotation
  hl-page:: 231
  id:: 6251204b-d57c-435b-bdd3-9ddbb34ce711
- 做间隔联结的两条流A和B，也必须基于相同的key；下界lowerBound应该小于等于上界upperBound，两者都可正可负；间隔联结目前只支持事件时间语义
  ls-type:: annotation
  hl-page:: 231
  id:: 6251205f-afb7-4109-9190-c82395fe9fa9
- [:span]
  ls-type:: annotation
  hl-page:: 231
  id:: 6251206d-2f4d-4108-935e-602233361f19
  hl-type:: area
  hl-stamp:: 1649483888550
- 间隔联结同样是一种内连接（inner join）。与窗口联结不同的是，interval join做匹配的时间段是基于流中数据的，所以并不确定；而且流B中的数据可以不只在一个区间内被匹配
  ls-type:: annotation
  hl-page:: 231
  id:: 625120aa-0fd3-43a1-889f-4899bf9ae1cd
- 间隔联结在代码中，是基于KeyedStream的联结（join）操作。DataStream在keyBy得到KeyedStream之后，可以调用.intervalJoin()来合并两条流，传入的参数同样是一个KeyedStream，两者的key类型应该一致；得到的是一个IntervalJoin类型。后续的操作同样是完全固定的：先通过.between()方法指定间隔的上下界，再调用.process()方法，定义对匹配数据对的处理操作
  ls-type:: annotation
  hl-page:: 231
  id:: 625120e1-ec2e-41cf-916c-504575b62209
- 除窗口联结和间隔联结之外，Flink还提供了一个“窗口同组联结”（window coGroup）操作。它的用法跟window join非常类似，也是将两条流合并之后开窗处理匹配的元素，调用时只需要将.join()换为.coGroup()就可以了
  ls-type:: annotation
  hl-page:: 235
  id:: 62512bbc-2c6d-47cd-8f39-79a8fc571d52
- [:span]
  ls-type:: annotation
  hl-page:: 235
  id:: 62512bcb-71b8-4d68-8c69-0b8a2e4db91c
  hl-type:: area
  hl-stamp:: 1649486795502
- 不同的是，这里的前两个参数不再是单独的每一组“配对”数据了，而是传入了可遍历的数据集合。也就是说，现在不会再去计算窗口中两条流数据集的笛卡尔积，而是直接把收集到的所有数据一次性传入，至于要怎样配对完全是自定义的。这样.coGroup()方法只会被调用一次，而且即使一条流的数据没有任何另一条流的数据匹配，也可以出现在集合中、当然也可以定义输出结果了
  ls-type:: annotation
  hl-page:: 235
  id:: 62512c61-64d3-4e0d-9ba5-caf8ccda6762
- coGroup操作比窗口的join更加通用，不仅可以实现类似SQL中的“内连接”（inner join），也可以实现左外连接（left outer join）、右外连接（right outer join）和全外连接（full outer join）。事实上，窗口join的底层，也是通过coGroup来实现的
  ls-type:: annotation
  hl-page:: 235
  id:: 62512c77-992b-4009-9539-06878e5809f3
- Flink处理机制的核心，就是“有状态的流式计算”
  ls-type:: annotation
  hl-page:: 238
  id:: 625140c4-b89e-4392-a42c-5089e0843a08
- 在流处理中，数据是连续不断到来和处理的。每个任务进行计算处理时，可以基于当前数据直接转换得到输出结果；也可以依赖一些其他数据。这些由一个任务维护，并且用来计算输出结果的所有数据，就叫作这个任务的状态
  ls-type:: annotation
  hl-page:: 238
  id:: 625140eb-17bc-4baf-884b-3cb9611c3e54
- [:span]
  ls-type:: annotation
  hl-page:: 239
  id:: 62514144-c79b-4407-82f8-ecf1dbdfd6eb
  hl-type:: area
  hl-stamp:: 1649492292943
- [:span]
  ls-type:: annotation
  hl-page:: 239
  id:: 6251418d-8e48-4f2b-b410-e8dc58aa16db
  hl-type:: area
  hl-stamp:: 1649492365037
- 9.1.2 状态的管理
  ls-type:: annotation
  hl-page:: 239
  id:: 6251421e-4bdd-4ad6-bc71-93981ab69b1f
- [:span]
  ls-type:: annotation
  hl-page:: 241
  id:: 6251454a-62c0-4f11-a9dc-f14fb4746252
  hl-type:: area
  hl-stamp:: 1649493322787
- [:span]
  ls-type:: annotation
  hl-page:: 241
  id:: 62514617-813a-4964-820b-5a9c9c44a3af
  hl-type:: area
  hl-stamp:: 1649493527285
- ls-type:: annotation
  hl-page:: 243
  id:: 62514878-7b0f-48c2-9b59-1f344800e8d3
  1. 值状态（ValueState）
- ls-type:: annotation
  hl-page:: 243
  id:: 625148a5-ba2e-48a0-986f-a47d9cd9a8f2
  2. 列表状态（ListState）
- ls-type:: annotation
  hl-page:: 244
  id:: 625148bf-d216-4769-81e0-15e72be48684
  3. 映射状态（MapState）
- ls-type:: annotation
  hl-page:: 244
  id:: 625148ca-0a82-4ab0-ae5f-2710de16595f
  4. 归约状态（ReducingState）
- ls-type:: annotation
  hl-page:: 244
  id:: 62514933-faab-4ff2-92f4-aa622db752f5
  5. 聚合状态（AggregatingState）
- ls-type:: annotation
  hl-page:: 261
  id:: 625393a1-c528-4403-bfe8-0dc4522c3a77
  1. 列表状态（ListState）
- ls-type:: annotation
  hl-page:: 261
  id:: 625393ac-4a9f-4ad3-9c48-9f4e5ef56554
  2. 联合列表状态（UnionListState）
- ls-type:: annotation
  hl-page:: 261
  id:: 625393b4-60bc-426b-9085-b27656a372f4
  3. 广播状态（BroadcastState）
- 内嵌RocksDB状态后端（EmbeddedRocksDBStateBackend）
  ls-type:: annotation
  hl-page:: 276
  id:: 6253c22f-c10e-4f1f-a274-e0cf098cca9a
- 哈希表状态后端（HashMapStateBackend）
  ls-type:: annotation
  hl-page:: 275
  id:: 6253c23d-dd68-4176-aa84-f96198379b5c
- HashMap和RocksDB两种状态后端最大的区别，就在于本地状态存放在哪里：前者是内存，后者是RocksDB。在实际应用中，选择那种状态后端，主要是需要根据业务需求在处理性能和应用的扩展性上做一个选择
  ls-type:: annotation
  hl-page:: 276
  id:: 6253c261-e451-47d6-be20-b784753c1859
- HashMapStateBackend是内存计算，读写速度非常快；但是，状态的大小会受到集群可用内存的限制，如果应用的状态随着时间不停地增长，就会耗尽内存资源
  ls-type:: annotation
  hl-page:: 276
  id:: 6253c26b-d720-4399-86a3-7ecfaa67e62a
- 而RocksDB是硬盘存储，所以可以根据可用的磁盘空间进行扩展，而且是唯一支持增量检查点的状态后端，所以它非常适合于超级海量状态的存储。不过由于每个状态的读写都需要做序列化/反序列化，而且可能需要直接从磁盘读取数据，这就会导致性能的降低，平均读写性能要比HashMapStateBackend慢一个数量级
  ls-type:: annotation
  hl-page:: 276
  id:: 6253c277-ef61-424c-a5c1-e462895868b2
- 配置默认的状态后端
  ls-type:: annotation
  hl-page:: 276
  id:: 6253c2c7-527e-4d19-b814-883cfccc426a
- 为每个作业（Per-job）单独配置状态后端
  ls-type:: annotation
  hl-page:: 277
  id:: 6253c2cf-37db-4dfb-a980-eae7b8a70754
- 本章从状态的概念和分类出发，详细介绍了Flink中的按键分区状态（Keyed State）和算子状态（Operator  State）的特点和用法，并对广播状态（Broadcast  State）做了进一步的展开说明。最后，我们还介绍了状态的持久化和状态后端，引出了检查点（checkpoint）的概念。检查点是一个非常重要的概念，是Flink容错机制的核心，我们将在下一章继续进行详细的讨论。
  ls-type:: annotation
  hl-page:: 278
  id:: 6253c325-ebce-4c07-9892-59bad352f709
- 在Flink中，有一套完整的容错机制（fault tolerance）来保证故障后的恢复，其中最重要的就是检查点（checkpoint）。在第九章中，我们已经介绍过检查点的基本概念和用途，接下来我们就深入探讨一下检查点的原理和Flink的容错机制
  ls-type:: annotation
  hl-page:: 278
  id:: 6253c3a2-7b64-4859-8719-d84f591ab24e
- 将之前某个时间点所有的状态保存下来，这份“存档”就是所谓的“检查点”（checkpoint）
  ls-type:: annotation
  hl-page:: 279
  id:: 6253c3c4-13e8-4dce-8482-d4879add0889
- 检查点是Flink容错机制的核心。这里所谓的“检查”，其实是针对故障恢复的结果而言的：故障恢复之后继续处理的结果，应该与发生故障前完全一致，我们需要“检查”结果的正确性。所以，有时又会把checkpoint叫作“一致性检查点”
  ls-type:: annotation
  hl-page:: 279
  id:: 6253c3d3-5644-4c9a-9d4c-5cd856d81862
- ls-type:: annotation
  hl-page:: 279
  id:: 6253c401-5d88-4cc4-846b-8a045125dd27
  1. 周期性的触发保存
- ls-type:: annotation
  hl-page:: 279
  id:: 6253c422-52a2-46f4-8d2f-29b3268f30d4
  2. 保存的时间点
- 当所有任务都恰好处理完一个相同的输入数据的时候，将它们的状态保存下来。首先，这样避免了除状态之外其他额外信息的存储，提高了检查点保存的效率。其次，一个数据要么就是被所有任务完整地处理完，状态得到了保存；要么就是没处理完，状态全部没保存：这就相当于构建了一个“事务”（transaction）。如果出现故障，我们恢复到之前保存的状态，故障时正在处理的所有数据都需要重新处理；所以我们只需要让源（source）任务向数据源重新提交偏移量、请求重放数据就可以了。这需要源任务可以把偏移量作为算子状态保存下来，而且外部数据源能够重置偏移量；Kafka就是满足这些要求的一个最好的例子
  ls-type:: annotation
  hl-page:: 280
  id:: 6253c480-d178-4a52-acc8-58602802e6b6
- ls-type:: annotation
  hl-page:: 280
  id:: 6253c497-aa8d-493c-bc92-d1c0de5f6f87
  3. 保存的具体流程
- （1）重启应用
  ls-type:: annotation
  hl-page:: 282
  id:: 6253c6f1-f9f6-4358-b721-1cf31c91debd
- （2）读取检查点，重置状态
  ls-type:: annotation
  hl-page:: 282
  id:: 6253c6f8-249c-4710-867a-fbb1a0ad6cd0
- （3）重放数据
  ls-type:: annotation
  hl-page:: 283
  id:: 6253c6fe-1da7-4a89-8451-9a520516267a
- （4）继续处理数据
  ls-type:: annotation
  hl-page:: 283
  id:: 6253c703-5b6d-4123-9851-7d8dff3bf72a
- 在Flink中，采用了基于Chandy-Lamport算法的分布式快照
  ls-type:: annotation
  hl-page:: 284
  id:: 6253c800-8cff-46af-8feb-25456e037129
- ls-type:: annotation
  hl-page:: 284
  id:: 6253c82b-1bd1-4111-a5d8-ad5cad0161da
  1. 检查点分界线（Barrier）
- 每个算子任务只要处理到这个barrier，就把当前的状态进行快照；在收到barrier之前，还是正常地处理之前的数据，完全不受影响。比如上图中，Source任务收到1号检查点保存指令时，读取完了三个数据，所以将偏移量3保存到外部存储中；而后将ID为1的barrier注入数据流；与此同时，Map任务刚刚收到上一条数据“hello”，而Sum任务则还在处理之前的第二条数据(world,  1)。下游任务不会在这时就立刻保存状态，而是等收到barrier时才去做快照，这时可以保证前三个数据都已经处理完了。同样地，下游任务做状态快照时，也不会影响上游任务的处理，每个任务的快照保存并行不悖，不会有暂停等待的时间
  ls-type:: annotation
  hl-page:: 286
  id:: 6253ca07-1a2b-492e-b579-1c0fca818e3c
- ls-type:: annotation
  hl-page:: 286
  id:: 6253ca11-0281-4d46-8390-8be817ed9eb7
  2. 分布式快照算法
- Flink使用了Chandy-Lamport算法的一种变体，被称为“异步分界线快照”（asynchronous barrier snapshotting）算法。算法的核心就是两个原则：当上游任务向多个并行下游任务发送barrier时，需要广播出去；而当多个上游任务向同一个下游任务传递barrier时，需要在下游任务执行“分界线对齐”（barrier alignment）操作，也就是需要等到所有并行分区的barrier都到齐，才可以开始状态的保存
  ls-type:: annotation
  hl-page:: 286
  id:: 6253ca50-fae3-44e3-89d6-d9b3a6b980d7
- [:span]
  ls-type:: annotation
  hl-page:: 286
  id:: 6253ca73-f5ca-495b-a05f-de3fc986638e
  hl-type:: area
  hl-stamp:: 1649658491323
- 由于分界线对齐要求先到达的分区做缓存等待，一定程度上会影响处理的速度；当出现背压（backpressure）时，下游任务会堆积大量的缓冲数据，检查点可能需要很久才可以保存完毕。为了应对这种场景，Flink 1.11之后提供了不对齐的检查点保存方式，可以将未处理的缓冲数据（in-flight data）也保存进检查点。这样，当我们遇到一个分区barrier时就不需等待对齐，而是可以直接启动状态的保存了
  ls-type:: annotation
  hl-page:: 289
  id:: 6253d0cd-4da5-4e96-a132-185c46e2d989
- 检查点的作用是为了故障恢复，我们不能因为保存检查点占据了大量时间、导致数据处理性能明显降低。为了兼顾容错性和处理性能，我们可以在代码中对检查点进行各种配置
  ls-type:: annotation
  hl-page:: 289
  id:: 6253d102-3da8-49b9-87e9-11d132a46ca5
- ls-type:: annotation
  hl-page:: 290
  id:: 6253d162-7dc3-410e-a931-449605c8a7c4
  2. 检查点存储（Checkpoint Storage）
- ls-type:: annotation
  hl-page:: 289
  id:: 6253d16b-16f5-4efb-babd-7ba92cb7d28d
  1. 启用检查点
- Flink主要提供了两种CheckpointStorage：作业管理器的堆内存（JobManagerCheckpointStorage）和文件系统（FileSystemCheckpointStorage）
  ls-type:: annotation
  hl-page:: 290
  id:: 6253d183-d524-44d0-b73f-a4735823b34a
- 对于实际生产应用，我们一般会将CheckpointStorage配置为高可用的分布式文件系统（HDFS，S3等）
  ls-type:: annotation
  hl-page:: 290
  id:: 6253d18c-4f3e-4244-aaf9-8b1f3867d2a2
- ls-type:: annotation
  hl-page:: 290
  id:: 6253d1a7-a016-430a-916b-dad141b0fa76
  3. 其他高级配置
- （1）检查点模式（CheckpointingMode）
  ls-type:: annotation
  hl-page:: 290
  id:: 6253d1b6-4441-4036-a0a9-f6e6ccffaf17
- （2）超时时间（checkpointTimeout）
  ls-type:: annotation
  hl-page:: 290
  id:: 6253d1bb-f4dd-4d09-a30e-00dc89ea59fd
- （3）最小间隔时间（minPauseBetweenCheckpoints）
  ls-type:: annotation
  hl-page:: 290
  id:: 6253d1c2-672e-4010-93d2-a24a6130297f
- （4）最大并发检查点数量（maxConcurrentCheckpoints）
  ls-type:: annotation
  hl-page:: 291
  id:: 6253d1dd-3797-40dd-b329-55e42f9a5799
- （5）开启外部持久化存储（enableExternalizedCheckpoints）
  ls-type:: annotation
  hl-page:: 291
  id:: 6253d1e5-7438-4c5d-82e2-cef501baf7e8
- （6）检查点异常时是否让整个任务失败（failOnCheckpointingErrors）
  ls-type:: annotation
  hl-page:: 291
  id:: 6253d1f7-88ed-425a-a684-12488ea164e4
- （7）不对齐检查点（enableUnalignedCheckpoints）
  ls-type:: annotation
  hl-page:: 291
  id:: 6253d202-6631-4c11-b1a0-972bf644234f
- 10.1.5保存点（Savepoint）
  ls-type:: annotation
  hl-page:: 292
  id:: 6253d349-11b7-4bc7-9ec9-398a2721477f
- 它的原理和算法与检查点完全相同，只是多了一些额外的元数据。事实上，保存点就是通过检查点的机制来创建流式作业状态的一致性镜像（consistentimage）的
  ls-type:: annotation
  hl-page:: 292
  id:: 6253d361-6ab0-4dd1-8191-35fc63a2859f
- 检查点是由Flink自动管理的，定期创建，发生故障之后自动读取进行恢复，这是一个“自动存盘”的功能；而保存点不会自动创建，必须由用户明确地手动触发保存操作
  ls-type:: annotation
  hl-page:: 292
  id:: 6253d386-62d9-4951-aa82-7154ca232df0
- 检查点主要用来做故障恢复，是容错机制的核心；保存点则更加灵活，可以用来做有计划的手动备份和恢复
  ls-type:: annotation
  hl-page:: 292
  id:: 6253d39d-c199-495c-bf3f-8ac9f83c52b1
- 完整的流处理应用，应该包括了数据源、流处理器和外部存储系统三个部分。这个完整应用的一致性，就叫作“端到端（end-to-end）的状态一致性”，它取决于三个组件中最弱的那一环。一般来说，能否达到at-least-once一致性级别，主要看数据源能够重放数据；而能否达到exactly-once级别，流处理器内部、数据源、外部存储都要有相应的保证机制
  ls-type:: annotation
  hl-page:: 295
  id:: 6253dbf4-c9ac-492c-855d-33517d808b9e
- 数据源可重放数据，或者说可重置读取数据偏移量，加上Flink的Source算子将偏移量作为状态保存进检查点，就可以保证数据不丢。这是达到at-least-once一致性语义的基本要求，当然也是实现端到端exactly-once的基本要求
  ls-type:: annotation
  hl-page:: 296
  id:: 6253e4da-412f-4bc3-b483-4aba689f82fd
- ls-type:: annotation
  hl-page:: 296
  id:: 6253e518-fdc7-4c16-b4fa-eba861488a06
  1. 幂等（idempotent）写入
- ls-type:: annotation
  hl-page:: 297
  id:: 6253e52b-55a7-4546-a779-94d8cbc5094c
  2. 事务（transactional）写入
- 需要注意，对于幂等写入，遇到故障进行恢复时，有可能会出现短暂的不一致。因为保存点完成之后到发生故障之间的数据，其实已经写入了一遍，回滚的时候并不能消除它们。如果有一个外部应用读取写入的数据，可能会看到奇怪的现象：短时间内，结果会突然“跳回”到之前的某个值，然后“重播”一段之前的数据。不过当数据的重放逐渐超过发生故障的点的时候，最终的结果还是一致的
  ls-type:: annotation
  hl-page:: 297
  id:: 6253e569-7989-4dc3-beeb-7d2bfc0bd1a6
- 事务有四个基本特性：原子性(Atomicity)、一致性(Correspondence)、隔离性(Isolation)和持久性(Durability)，这就是著名的ACID
  ls-type:: annotation
  hl-page:: 297
  id:: 6253e59c-516e-4368-9fcf-c585a7ccf4ae
- 事务写入的基本思想就是：用一个事务来进行数据向外部系统的写入，这个事务是与检查点绑定在一起的。当Sink任务遇到barrier时，开始保存状态的同时就开启一个事务，接下来所有数据的写入都在这个事务中；待到当前检查点保存完毕时，将事务提交，所有写入的数据就真正可用了。如果中间过程出现故障，状态会回退到上一个检查点，而当前事务没有正常关闭（因为当前检查点没有保存完），所以也会回滚，写入到外部的数据就被撤销了
  ls-type:: annotation
  hl-page:: 297
  id:: 6253e5c6-bb64-4b72-bfe9-cd78f359e346
- 我们发现，事务提交是需要外部存储系统支持事务的，否则没有办法真正实现写入的回撤。那对于一般不支持事务的存储系统，能够实现事务写入呢
  ls-type:: annotation
  hl-page:: 297
  id:: 6253e60f-c373-4f39-909c-d0c9a83f423f
- 我们会发现，这种方式类似于检查点完成时做一个批处理，一次性的写入会带来一些性能上的问题；而优点就是比较简单，由于数据提前在状态后端中做了缓存，所以无论什么外部存储系统，理论上都能用这种方式一批搞定。在Flink中DataStream  API提供了一个模板类GenericWriteAheadSink，用来实现这种事务型的写入方式
  ls-type:: annotation
  hl-page:: 297
  id:: 6253e687-4ba8-422a-b07a-cdbd22aa3d97
- 分成两个阶段：先做“预提交”，等检查点完成之后再正式提交。这种提交方式是真正基于事务的，它需要外部系统提供事务支持
  ls-type:: annotation
  hl-page:: 298
  id:: 6253e6d2-dc5d-423c-b00c-3b775b2cb914
- 2PC协议不仅真正意义上实现了exactly-once，而且通过搭载Flink的检查点机制来实现事务，只给系统增加了很少的开销
  ls-type:: annotation
  hl-page:: 298
  id:: 6253e764-25db-4e5c-8b89-342e425cb1c0
- link提供了TwoPhaseCommitSinkFunction接口，方便我们自定义实现两阶段提交的SinkFunction的实现，提供了真正端到端的exactly-once保证
  ls-type:: annotation
  hl-page:: 298
  id:: 6253e76e-09aa-476d-92d0-165c2b0536ae
- 可见，2PC在实际应用同样会受到比较大的限制。具体在项目中的选型，最终还应该是一致性级别和处理性能的权衡考量
  ls-type:: annotation
  hl-page:: 298
  id:: 6253e819-82c3-4bd8-afd5-2f3df41540e6
- 10.3.3 Flink和Kafka连接时的精确一次保证
  ls-type:: annotation
  hl-page:: 298
  id:: 6253eaef-770f-4ec0-8bfc-d0fde64b11d3
- 最直观的创建表的方式，就是通过连接器（connector）连接到一个外部系统，然后定义出对应的表结构。例如我们可以连接到Kafka或者文件系统，将存储在这些外部系统的数据以“表”的形式定义出来，这样对表的读写就可以通过连接器转换成对外部系统的读写了。当我们在表环境中读取这张表，连接器就会从外部系统读取数据并进行转换；而当我们向这张表写入数据，连接器就会将数据输出（Sink）到外部系统中
  ls-type:: annotation
  hl-page:: 309
  id:: 6255138a-7c0d-41d5-97d5-7564d310dd77
- 对一个表的查询（Query）操作，就对应着流数据的转换（Transform）处理
  ls-type:: annotation
  hl-page:: 311
  id:: 6255158a-a6ef-4264-b231-3def7889e51d
- ls-type:: annotation
  hl-page:: 311
  id:: 625515ad-2cc6-4101-9ee6-c737a55a0cb3
  1. 执行SQL进行查询
- ls-type:: annotation
  hl-page:: 312
  id:: 625515b6-4cf6-4076-af5a-1e6d260ea333
  2. 调用Table API进行查询
- ls-type:: annotation
  hl-page:: 312
  id:: 625515cb-85f3-488b-b5cd-a8164f6f4fc8
  3. 两种API的结合使用
- 表的创建和查询，就对应着流处理中的读取数据源（Source）和转换（Transform）；而最后一个步骤Sink，也就是将结果数据输出到外部系统，就对应着表的输出操作
  ls-type:: annotation
  hl-page:: 313
  id:: 62551cee-6d38-42f7-a471-1f72e966bb88
- ls-type:: annotation
  hl-page:: 314
  id:: 62551d28-22c4-4fbf-ae2c-996e4d64d5f9
  1. 将表（Table）转换成流（DataStream）
- ls-type:: annotation
  hl-page:: 315
  id:: 62551d35-ce6a-4225-9eb1-bec347a67897
  2. 将流（DataStream）转换成表（Table）
- ls-type:: annotation
  hl-page:: 316
  id:: 62551d54-3f53-4ea1-a91c-8893e18f3c81
  3. 支持的数据类型
- toDataStream()
  ls-type:: annotation
  hl-page:: 314
  id:: 62552ae9-09b4-415d-9d45-be8cd248dab6
- toChangelogStream()
  ls-type:: annotation
  hl-page:: 314
  id:: 62552af4-7cc9-4984-9fe3-81445329a362
- [:span]
  ls-type:: annotation
  hl-page:: 314
  id:: 62552b09-bdf9-43fa-9661-a3e1f4a7aef3
  hl-type:: area
  hl-stamp:: 1649748745993
- fromDataStream()
  ls-type:: annotation
  hl-page:: 315
  id:: 62552b25-0636-413d-b046-bfa68823f49f
- createTemporaryView()
  ls-type:: annotation
  hl-page:: 315
  id:: 62552b33-8471-4e31-88a4-cfa737b234a4
- fromChangelogStream ()
  ls-type:: annotation
  hl-page:: 316
  id:: 62552b3d-9e8d-452f-af7f-d57b963112e9
- （1）原子类型
  ls-type:: annotation
  hl-page:: 316
  id:: 62552b65-ae27-4697-84dc-6e7b69956948
- （2）Tuple类型
  ls-type:: annotation
  hl-page:: 316
  id:: 62552b6c-d473-4055-bb96-db1543dce882
- ls-type:: annotation
  hl-page:: 317
  id:: 62552bb8-5aab-44ad-8721-0f88aecf186f
- （3）POJO 类型
  ls-type:: annotation
  hl-page:: 317
  id:: 62552bba-b27d-4dae-97ba-8e02e26912b3
- ls-type:: annotation
  hl-page:: 317
  id:: 62552bc2-b1c5-44e8-8d20-57f206b471b1
- （4）Row类型
  ls-type:: annotation
  hl-page:: 317
  id:: 62552bcd-ae41-4b4d-86dd-f1617e515888
- ls-type:: annotation
  hl-page:: 320
  id:: 62552da6-5944-4d50-8de3-10b0455a454e
  1. 动态表（Dynamic Tables）
- ls-type:: annotation
  hl-page:: 320
  id:: 62552db2-a0d8-41ca-b4ef-f58819fa2ca7
  2. 持续查询（Continuous Query）
- [:span]
  ls-type:: annotation
  hl-page:: 321
  id:: 625530f1-da93-49b7-922d-d06ff6415928
  hl-type:: area
  hl-stamp:: 1649750257562
- [:span]
  ls-type:: annotation
  hl-page:: 322
  id:: 625531bd-461b-43be-9aa5-2beb05fa7f40
  hl-type:: area
  hl-stamp:: 1649750461489
- [:span]
  ls-type:: annotation
  hl-page:: 323
  id:: 6255322a-5a8b-4674-bc23-2f1e9ae175d8
  hl-type:: area
  hl-stamp:: 1649750570905
- 追加查询（Append  Query），它定义的结果表的更新日志（changelog）流中只有INSERT操作。追加查询得到的结果表，转换成DataStream调用方法没有限制，可以直接用toDataStream()，也可以像更新查询一样调用toChangelogStream()
  ls-type:: annotation
  hl-page:: 324
  id:: 62553324-15ab-45d7-9dc8-1198af59bde2
- 这样看来，我们似乎可以总结一个规律：只要用到了聚合，在之前的结果上有叠加，就会产生更新操作，就是一个更新查询。但事实上，更新查询的判断标准是结果表中的数据是否会有UPDATE操作，如果聚合的结果不再改变，那么同样也不是更新查询
  ls-type:: annotation
  hl-page:: 324
  id:: 62553338-4ca4-4874-9f74-31035c29f180
- [:span]
  ls-type:: annotation
  hl-page:: 325
  id:: 625533d1-021f-4487-ad63-3a747aadfaef
  hl-type:: area
  hl-stamp:: 1649750993804
- 在实际应用中，有些持续查询会因为计算代价太高而受到限制。所谓的“代价太高”，可能是由于需要维护的状态持续增长，也可能是由于更新数据的计算太复杂
  ls-type:: annotation
  hl-page:: 327
  id:: 62553468-e6a6-4f38-80cc-540050a238af
- 在Flink中，Table API和SQL支持三种编码方式
  ls-type:: annotation
  hl-page:: 328
  id:: 6255354c-b0fc-4ada-8a92-6f93c8a9ddee
- 仅追加（Append-only）流
  ls-type:: annotation
  hl-page:: 328
  id:: 62553554-73b9-4a9a-9791-45baf4ba83c5
- 撤回（Retract）流
  ls-type:: annotation
  hl-page:: 328
  id:: 62553559-0930-4942-b41f-0d3a4757e8b4
- 更新插入（Upsert）流
  ls-type:: annotation
  hl-page:: 329
  id:: 62553560-dc5f-4aa0-b697-4ed1f942a380
- 需要动态表中必须有唯一的键（key）。通过这个key进行查询，如果存在对应的数据就做更新（update），如果不存在就直接插入（insert）
  ls-type:: annotation
  hl-page:: 329
  id:: 625535f4-7572-427a-9a88-77171f616e0d
- 收到这条流中数据的外部系统，也需要知道这唯一的键（key），这样才能正确地处理消息
  ls-type:: annotation
  hl-page:: 329
  id:: 625535fe-8c3a-4c56-a568-81679d489afa
- 在代码里将动态表转换为DataStream时，只支持仅追加（append-only）和撤回（retract）流，我们调用toChangelogStream()得到的其实就是撤回流；这也很好理解，DataStream中并没有key的定义，所以只能通过两条消息一减一增来表示更新操作。而连接到外部系统时，则可以支持不同的编码方法，这取决于外部系统本身的特性
  ls-type:: annotation
  hl-page:: 329
  id:: 6255360e-50d1-473e-8d68-144ad93bd1b5
- 在Table API和SQL中，会给表单独提供一个逻辑上的时间字段，专门用来在表处理程序中指示时间
  ls-type:: annotation
  hl-page:: 330
  id:: 6255392b-7da9-4d65-aa96-237af57c7411
- ls-type:: annotation
  hl-page:: 330
  id:: 625539a0-c1b3-43a4-be23-97bf834c2ac1
  1. 在创建表的DDL中定义
- Flink中支持的事件时间属性数据类型必须为TIMESTAMP或者TIMESTAMP_LTZ。这里TIMESTAMP_LTZ是指带有本地时区信息的时间戳（TIMESTAMP  WITH  LOCAL  TIME ZONE）；一般情况下如果数据中的时间戳是“年-月-日-时-分-秒”的形式，那就是不带时区信息的，可以将事件时间属性定义为TIMESTAMP类型
  ls-type:: annotation
  hl-page:: 331
  id:: 625539f8-c868-4dc2-8cb5-5f6e8e653ffc
- 而如果原始的时间戳就是一个长整型的毫秒数，这时就需要另外定义一个字段来表示事件时间属性，类型定义为TIMESTAMP_LTZ会更方便
  ls-type:: annotation
  hl-page:: 331
  id:: 625539ff-590a-42f0-9aef-43dda244f83a
- 这里我们另外定义了一个字段ts_ltz，是把长整型的ts转换为TIMESTAMP_LTZ得到的；进而使用WATERMARK语句将它设为事件时间属性，并设置5秒的水位线延迟
  ls-type:: annotation
  hl-page:: 331
  id:: 62553a37-fa2a-467b-965b-d8c263debf8c
- ls-type:: annotation
  hl-page:: 331
  id:: 62553a57-32e6-43eb-a751-e4c34d10f230
  2. 在数据流转换为表时定义
- 相比之下处理时间就比较简单了，它就是我们的系统时间，使用时不需要提取时间戳（timestamp）和生成水位线（watermark）。因此在定义处理时间属性时，必须要额外声明一个字段，专门用来保存当前的处理时间
  ls-type:: annotation
  hl-page:: 332
  id:: 62554311-c581-4134-b602-c3b27fa74b1c
- ls-type:: annotation
  hl-page:: 332
  id:: 6255431a-a128-48df-8dcd-c1ff7605b73e
  1. 在创建表的DDL中定义
- ls-type:: annotation
  hl-page:: 332
  id:: 62554322-bf67-4e26-b058-7ce2ccd622ad
  2. 在数据流转换为表时定义
- ls-type:: annotation
  hl-page:: 333
  id:: 625543ad-b397-46dc-b491-940dfb30413c
  2. 窗口表值函数（Windowing TVFs，新版本）
- （1）滚动窗口（TUMBLE）
  ls-type:: annotation
  hl-page:: 334
  id:: 62554e23-67a2-4c75-9aff-d4a380e88ba6
- （2）滑动窗口（HOP）
  ls-type:: annotation
  hl-page:: 334
  id:: 62554e2a-caeb-443e-a020-ad8c0084ac1e
- （3）累积窗口（CUMULATE）
  ls-type:: annotation
  hl-page:: 334
  id:: 62554e31-8844-4dfe-940e-38eba7551833
- Flink 中的SQL是流处理与标准SQL结合的产物，所以聚合查询也可以分成两种：流处理中特有的聚合（主要指窗口聚合），以及SQL原生的聚合查询方式
  ls-type:: annotation
  hl-page:: 336
  id:: 62554e63-dfc8-4d4a-a3d8-56e6ea3b2542
- 分组聚合既是SQL原生的聚合查询，也是流处理中的聚合操作，这是实际应用中最常见的聚合方式。当然，使用的聚合函数一般都是系统内置的，如果希望实现特殊需求也可以进行自定义
  ls-type:: annotation
  hl-page:: 337
  id:: 62554f49-cd1a-43ec-a931-6511e2b576c4
- 在Flink的Table API和SQL中，窗口的计算是通过“窗口聚合”（window aggregation）来实现的
  ls-type:: annotation
  hl-page:: 337
  id:: 62554f6e-8840-43af-824b-a4797c6cfad8
- 与分组聚合类似，窗口聚合也需要调用SUM()、MAX()、MIN()、COUNT()一类的聚合函数，通过GROUP BY子句来指定分组的字段
  ls-type:: annotation
  hl-page:: 337
  id:: 62554f7d-42da-4d36-8248-3b0f099c4a59
- 只不过窗口聚合时，需要将窗口信息作为分组key的一部分定义出来
  ls-type:: annotation
  hl-page:: 337
  id:: 62554f88-cc1b-48ea-b4d9-eddd612cce24
- 1.13版本开始使用了“窗口表值函数”（Windowing TVF），窗口本身返回的是就是一个表，所以窗口会出现在FROM后面，GROUP BY后面的则是窗口新增的字段window_start和window_end
  ls-type:: annotation
  hl-page:: 337
  id:: 62554f97-a55e-4cd0-afef-ded15d295882
- 与标准SQL中一致，Flink  SQL中的开窗函数也是通过OVER子句来实现的，所以有时开窗聚合也叫作“OVER聚合”（Over Aggregation）
  ls-type:: annotation
  hl-page:: 340
  id:: 625555c0-af03-4f47-8529-18bd4109e10b
- PARTITION BY（可选）
  ls-type:: annotation
  hl-page:: 340
  id:: 6255560a-3305-4083-86cd-f28109030b71
- ORDER BY
  ls-type:: annotation
  hl-page:: 340
  id:: 62555615-f117-41d8-adce-5ac6454bd780
- 开窗范围
  ls-type:: annotation
  hl-page:: 341
  id:: 6255561e-b0d6-4907-ba8c-978d45b7c067
- 范围间隔
  ls-type:: annotation
  hl-page:: 341
  id:: 62555625-b1a2-4734-b83b-9b1e088c3dc1
- 行间隔
  ls-type:: annotation
  hl-page:: 341
  id:: 6255562a-5916-409d-a4c2-9020fddce33b
- 在SQL中，也可以用WINDOW子句来在SELECT外部单独定义一个OVER窗口
  ls-type:: annotation
  hl-page:: 341
  id:: 62555750-c2e3-4e6d-9eb5-1ea7ff1784c8
- 在标准SQL中，可以将多个表连接合并起来，从中查询出想要的信息；这种操作就是表的联结（Join）。在Flink SQL中，同样支持各种灵活的联结（Join）查询，操作的对象是动态表
  ls-type:: annotation
  hl-page:: 347
  id:: 62556ef9-9495-4bde-bc1c-7f547178abcd
- FlinkSQL中的联结查询大体上也可以分为两类：SQL原生的联结查询方式，和流处理中特有的联结查询
  ls-type:: annotation
  hl-page:: 347
  id:: 62556f10-2f77-404f-bfbd-1d09ab46a87c
- ls-type:: annotation
  hl-page:: 347
  id:: 62556f38-ce83-4289-ad7f-b6ee58a1c9f1
  1. 等值内联结（INNEREqui-JOIN）
- ls-type:: annotation
  hl-page:: 347
  id:: 62556f3f-cdc0-4f81-b2b8-eeefa3302a9a
  2. 等值外联结（OUTEREqui-JOIN）
- 这部分知识与标准SQL中是完全一样的，这里不再赘述
  ls-type:: annotation
  hl-page:: 348
  id:: 62556f6a-7c92-4216-9e64-ca53a8ddc236
- 间隔联结（IntervalJoin）返回的，同样是符合约束条件的两条中数据的笛卡尔积。只不过这里的“约束条件”除了常规的联结条件外，还多了一个时间间隔的限制。具体语法有以下要点
  ls-type:: annotation
  hl-page:: 348
  id:: 62556fc0-727e-421c-a24a-73913fd76a11
- 两表的联结
  ls-type:: annotation
  hl-page:: 348
  id:: 62556fc5-e1de-4f86-8e06-eb5106a090c1
- 联结条件
  ls-type:: annotation
  hl-page:: 348
  id:: 62556fc9-3d0c-43a7-8d32-b40a0739df11
- 时间间隔限制
  ls-type:: annotation
  hl-page:: 348
  id:: 62556fce-dfc8-42db-b7b0-dc46976ef211
- 判断两者相等，这是最强的时间约束，要求两表中数据的时间必须完全一致才能匹配；一般情况下，我们还是会放宽一些，给出一个间隔。间隔的定义可以用<，<=，>=，>这一类的关系不等式，也可以用BETWEEN ... AND ...这样的表达式
  ls-type:: annotation
  hl-page:: 349
  id:: 62557374-b0ce-4876-85b9-67374199fbaf
- Table API中的函数是通过数据对象的方法调用来实现的；而SQL则是直接引用函数名称，传入数据作为参数
  ls-type:: annotation
  hl-page:: 349
  id:: 6255739d-143e-4164-9049-a26b73326287
- 由于Table API是内嵌在Java语言中的，很多方法需要在类中额外添加，因此扩展功能比较麻烦，目前支持的函数比较少；而且Table API也不如SQL的通用性强，所以一般情况下较少使用
  ls-type:: annotation
  hl-page:: 349
  id:: 625573b0-dbe1-4959-993d-76e5ac919eee
- 系统函数（System Functions）也叫内置函数（Built-in Functions），是在系统中预先实现好的功能模块。我们可以通过固定的函数名直接调用，实现想要的转换操作。Flink SQL提供了大量的系统函数，几乎支持所有的标准SQL中的操作，这为我们使用SQL编写流处理程序提供了极大的方便
  ls-type:: annotation
  hl-page:: 350
  id:: 625573e9-186e-400a-be2a-096a1a9aa6db
- 标量函数指的就是只对输入数据做转换操作、返回一个值的函数。这里的输入数据对应在表中，一般就是一行数据中1个或多个字段，因此这种操作有点像流处理转换算子中的map。另外，对于一些没有输入参数、直接可以得到唯一结果的函数，也属于标量函数
  ls-type:: annotation
  hl-page:: 350
  id:: 62557422-624e-4991-8a19-2d8a3a17c6b3
- 比较函数（Comparison Functions）
  ls-type:: annotation
  hl-page:: 350
  id:: 62557435-b60d-4e84-90cd-3561a0b99019
- 逻辑函数（Logical Functions）
  ls-type:: annotation
  hl-page:: 350
  id:: 6255743d-c3a2-46c4-aed3-624834fdf4a6
- 算术函数（Arithmetic Functions）
  ls-type:: annotation
  hl-page:: 350
  id:: 62557447-a6f5-4c93-94ee-d12c57700b81
- 字符串函数（String Functions）
  ls-type:: annotation
  hl-page:: 351
  id:: 6255744f-ea60-4b49-a769-151c31894622
- 时间函数（Temporal Functions）
  ls-type:: annotation
  hl-page:: 351
  id:: 62557455-0d37-44b5-bbf2-750b1135b014
- 聚合函数是以表中多个行作为输入，提取字段进行聚合操作的函数，会将唯一的聚合值作为结果返回。聚合函数应用非常广泛，不论分组聚合、窗口聚合还是开窗（Over）聚合，对数据的聚合操作都可以用相同的函数来定义
  ls-type:: annotation
  hl-page:: 351
  id:: 6255748b-7a50-4306-8189-fd2adcb554d1
- 标准SQL中常见的聚合函数Flink  SQL都是支持的，目前也在不断扩展
  ls-type:: annotation
  hl-page:: 351
  id:: 62557497-297f-4e3e-9154-39af983838f4
- COUNT(*)
  ls-type:: annotation
  hl-page:: 351
  id:: 625574a1-8f2f-4d2e-aae6-6f0c83936f7b
- SUM([ ALL | DISTINCT ] expression)
  ls-type:: annotation
  hl-page:: 351
  id:: 625574a6-7e8d-479c-beb0-3b9f93e84f2b
- RANK()
  ls-type:: annotation
  hl-page:: 351
  id:: 625574ab-b766-4174-85ef-4867e1941b33
- ROW_NUMBER()
  ls-type:: annotation
  hl-page:: 351
  id:: 625574b0-1bf3-46ef-865f-e99a863de297
- Flink的TableAPI和SQL提供了多种自定义函数的接口，以抽象类的形式定义。当前UDF主要有以下几类
  ls-type:: annotation
  hl-page:: 352
  id:: 62557527-b312-4530-8a95-ea3116cee242
- 标量函数（ScalarFunctions）：将输入的标量值转换成一个新的标量值
  ls-type:: annotation
  hl-page:: 352
  id:: 6255752d-2f9a-4098-be83-7bdbed1c4767
- 表函数（TableFunctions）：将标量值转换成一个或多个新的行数据，也就是扩展成一个表
  ls-type:: annotation
  hl-page:: 352
  id:: 62557531-c142-43df-910d-33af4bbb4c29
- 聚合函数（AggregateFunctions）：将多行数据里的标量值转换成一个新的标量值
  ls-type:: annotation
  hl-page:: 352
  id:: 62557536-f10c-43dd-8bb3-8432c5f96b33
- 表聚合函数（TableAggregateFunctions）：将多行数据里的标量值转换成一个或多个新的行数据
  ls-type:: annotation
  hl-page:: 352
  id:: 6255753a-4dff-4f13-a4d9-46660e4f3808
- 可见，SQL的调用方式更加方便，我们后续依然会以SQL为例介绍UDF的用法
  ls-type:: annotation
  hl-page:: 353
  id:: 62557613-9d1b-4047-9016-244d14ac52c2
- 自定义标量函数可以把0个、1个或多个标量值转换成一个标量值，它对应的输入是一行数据中的字段，输出则是唯一的值。所以从输入和输出表中行数据的对应关系看，标量函数是“一对一”的转换
  ls-type:: annotation
  hl-page:: 353
  id:: 6255763f-a746-4076-b04e-01c8a70a7fd3
- 想要实现自定义的标量函数，我们需要自定义一个类来继承抽象类ScalarFunction，并实现叫作eval() 的求值方法
  ls-type:: annotation
  hl-page:: 353
  id:: 62557647-ff0d-46b1-8713-cf3f3822c659
- 跟标量函数一样，表函数的输入参数也可以是0个、1个或多个标量值；不同的是，它可以返回任意多行数据。“多行数据”事实上就构成了一个表，所以“表函数”可以认为就是返回一个表的函数，这是一个“一对多”的转换关系。之前我们介绍过的窗口TVF，本质上就是表函数
  ls-type:: annotation
  hl-page:: 354
  id:: 625578bf-91f1-4c29-aa8a-4f405c318aeb
- 要实现自定义的表函数，需要自定义类来继承抽象类TableFunction，内部必须要实现的也是一个名为eval 的求值方法
  ls-type:: annotation
  hl-page:: 354
  id:: 625578d9-7429-4dfd-9d20-424c9a48f658
- 与标量函数不同的是，TableFunction类本身是有一个泛型参数T的，这就是表函数返回数据的类型；而eval()方法没有返回类型，内部也没有return语句，是通过调用collect()方法来发送想要输出的行数据的
  ls-type:: annotation
  hl-page:: 354
  id:: 625578e7-6d1e-47ce-9c33-c213ff4c83c6
- 用户自定义聚合函数（UserDefined AGGregate function，UDAGG）会把一行或多行数据（也就是一个表）聚合成一个标量值。这是一个标准的“多对一”的转换
  ls-type:: annotation
  hl-page:: 355
  id:: 62557c89-7cba-4780-9bce-706df8eaca19
- 自定义聚合函数需要继承抽象类AggregateFunction。AggregateFunction有两个泛型参数<T, ACC>，T表示聚合输出的结果类型，ACC则表示聚合的中间状态类型
  ls-type:: annotation
  hl-page:: 355
  id:: 62557c93-792b-441c-98fb-64951d252568
- 首先，它需要创建一个累加器（accumulator），用来存储聚合的中间结果。这与DataStreamAPI中的AggregateFunction非常类似，累加器就可以看作是一个聚合状态。调用createAccumulator()方法可以创建一个空的累加器
  ls-type:: annotation
  hl-page:: 355
  id:: 62557c9b-7f66-46f2-a0da-14aaae888d9c
- 对于输入的每一行数据，都会调用accumulate()方法来更新累加器，这是聚合的核心过程
  ls-type:: annotation
  hl-page:: 355
  id:: 62557ca1-32b3-4793-aef8-4a23c53ca917
- 当所有的数据都处理完之后，通过调用getValue()方法来计算并返回最终的结果
  ls-type:: annotation
  hl-page:: 355
  id:: 62557ca8-a98b-49de-96da-3ee5af033c9c
- 所以，每个AggregateFunction 都必须实现以下几个方法
  ls-type:: annotation
  hl-page:: 355
  id:: 62557cb0-0309-4ee8-ba0f-a2b3740d1c7a
- createAccumulator()
  ls-type:: annotation
  hl-page:: 355
  id:: 62557cb6-d431-4d13-9a4a-ee5925271c39
- 这是创建累加器的方法。没有输入参数，返回类型为累加器类型ACC
  ls-type:: annotation
  hl-page:: 355
  id:: 62557cbb-79e4-49db-a20d-eea26ad6b14d
- accumulate()
  ls-type:: annotation
  hl-page:: 355
  id:: 62557cc7-244e-46bb-ae6b-ee16a35e30d0