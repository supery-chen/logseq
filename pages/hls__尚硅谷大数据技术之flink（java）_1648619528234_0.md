- 这里需要提到Flink中的几个关键组件：客户端（Client）、作业管理器（JobManager）和任务管理器（TaskManager）
  ls-type:: annotation
  hl-page:: 28
  id:: 62440a36-c97d-4cb0-939a-621b0e56e98b
- [:span]
  ls-type:: annotation
  hl-page:: 29
  id:: 62440a74-bd5d-41e4-b278-4d1f25aaba68
  hl-type:: area
  hl-stamp:: 1648626292381
- 会话模式比较适合于单个规模小、执行时间短的大量作业
  ls-type:: annotation
  hl-page:: 38
  id:: 62450ce5-4bd3-430d-ad09-3c77d87ceace
- 单作业模式在生产环境运行更加稳定，所以是实际应用的首选模式
  ls-type:: annotation
  hl-page:: 38
  id:: 62450cfa-2832-4b40-b6f9-7b46e358410e
- 我们需要为每一个提交的应用单独启动一个JobManager，也就是创建一个集群。这个JobManager只为执行这一个应用而存在，执行结束之后JobManager也就关闭了，这就是所谓的应用模式
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d13-0ed7-4469-962b-e908d22704a6
- 在会话模式下，集群的生命周期独立于集群上运行的任何作业的生命周期，并且提交的所有作业共享资源。而单作业模式为每个提交的作业创建一个集群，带来了更好的资源隔离，这时集群的生命周期与作业的生命周期绑定。最后，应用模式为每个应用程序创建一个会话集群，在JobManager上直接调用应用程序的main()方法
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d33-59e4-48c0-ad47-02c1bc2cd5f3
- YARN上部署的过程是：客户端把Flink应用提交给Yarn的ResourceManager, Yarn的ResourceManager会向Yarn的NodeManager申请容器。在这些容器上，Flink会部署JobManager和TaskManager的实例，从而启动集群。Flink会根据运行在JobManger上的作业所需要的Slot数量动态分配TaskManager资源。
  ls-type:: annotation
  hl-page:: 42
  id:: 62450dec-7154-4f5d-819e-fc4150cff13e
- [:span]
  ls-type:: annotation
  hl-page:: 49
  id:: 62451f28-540a-4c62-abfe-46958ef9aef6
  hl-type:: area
  hl-stamp:: 1648697128409
- Flink的运行时架构中，最重要的就是两大组件：作业管理器（JobManger）和任务管理器（TaskManager）。对于一个提交执行的作业，JobManager是真正意义上的“管理者”（Master），负责管理调度，所以在不考虑高可用的情况下只能有一个；而TaskManager是“工作者”（Worker、Slave），负责执行任务处理数据，所以可以有一个或多个。Flink的作业提交和任务处理时的系统如图4-1所示。
  ls-type:: annotation
  hl-page:: 48
  id:: 62451f57-78fd-4be4-ad93-a47a58f42523
- [:span]
  ls-type:: annotation
  hl-page:: 51
  id:: 62453fc2-a342-43cb-8e2c-678f7917fb1d
  hl-type:: area
  hl-stamp:: 1648705474055
- [:span]
  ls-type:: annotation
  hl-page:: 52
  id:: 62454063-0020-4aa4-b678-18e16e071e4f
  hl-type:: area
  hl-stamp:: 1648705635790
- [:span]
  ls-type:: annotation
  hl-page:: 53
  id:: 62454115-6eba-4154-ab1d-e057d767c4a2
  hl-type:: area
  hl-stamp:: 1648705813730
- [:span]
  ls-type:: annotation
  hl-page:: 54
  id:: 62454135-1954-4edb-99bf-2f6d9975f66e
  hl-type:: area
  hl-stamp:: 1648705845181
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 624541f2-189f-4995-a375-3ef37f35add8
  hl-type:: area
  hl-stamp:: 1648706034535
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 6245466b-87c3-47f2-b8e0-eb30d8b2cfa7
  hl-type:: area
  hl-stamp:: 1648707179638
- [:span]
  ls-type:: annotation
  hl-page:: 57
  id:: 62454701-8930-4021-934b-388c85a330e5
  hl-type:: area
  hl-stamp:: 1648707329143
- 一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。这样，包含并行子任务的数据流，就是并行数据流，它需要多个分区（stream  partition）来分配并行任务。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。如图4-8所示，当前数据流中有source、map、window、sink四个算子，除最后sink，其他算子的并行度都为2。整个程序包含了7个子任务，至少需要2个分区来并行执行。我们可以说，这段流处理程序的并行度就是2。
  ls-type:: annotation
  hl-page:: 57
  id:: 6245471b-13ef-4cfb-975d-69af821a09d0
- [:span]
  ls-type:: annotation
  hl-page:: 61
  id:: 62454a8d-db87-42a7-838d-611c206f0a5e
  hl-type:: area
  hl-stamp:: 1648708237078
- [:span]
  ls-type:: annotation
  hl-page:: 63
  id:: 62454e39-97d3-4303-a24a-a1467fc124fa
  hl-type:: area
  hl-stamp:: 1648709177499
- 我们可以通过集群的配置文件来设定TaskManager的slot数量：taskmanager.numberOfTaskSlots: 8通过调整slot的数量，我们就可以控制子任务之间的隔离级别。具体来说，如果一个TaskManager只有一个slot，那将意味着每个任务都会运行在独立的JVM中（当然，该JVM可能是通过一个特定的容器启动的）；而一个TaskManager设置多个slot则意味着多个子任务可以共享同一个JVM。它们的区别在于：前者任务之间完全独立运行，隔离级别更高、彼此间的影响可以降到最小；而后者在同一个JVM进程中运行的任务，将共享TCP连接和心跳消息，也可能共享数据集和数据结构，这就减少了每个任务的运行开销，在降低隔离级别的同时提升了性能。需要注意的是，slot目前仅仅用来隔离内存，不会涉及CPU的隔离。在具体应用时，可以将slot数量配置为机器的CPU核心数，尽量避免不同任务之间对CPU的竞争。这也是开发环境默认并行度设为机器CPU数量的原因。
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e59-5ef5-47ad-85b9-66b9677fa165
- [:span]
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e82-ff8f-4b89-b726-614cb95daff5
  hl-type:: area
  hl-stamp:: 1648709252945
- 默认情况下，Flink是允许子任务共享slot的
  ls-type:: annotation
  hl-page:: 65
  id:: 62454e91-b72e-43b4-86a2-5c5565148a9e
- 只要属于同一个作业，那么对于不同任务节点的并行子任务，就可以放到同一个slot上执行。所以对于第一个任务节点source→map，它的6个并行子任务必须分到不同的slot上（如果在同一slot就没法数据并行了），而第二个任务节点keyBy/window/apply的并行子任务却可以和第一个任务节点共享slot。于是最终结果就变成了：每个任务节点的并行子任务一字排开，占据不同的slot；而不同的任务节点的子任务可以共享slot。一个slot中，可以将程序处理的所有任务都放在这里执行，我们把它叫作保存了整个作业的运行管道（pipeline）。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454ee2-c050-42d0-a67a-8d1e48e7e94f
- 当我们将资源密集型和非密集型的任务同时放到一个slot中，它们就可以自行分配对资源占用的比例，从而保证最重的活平均分配给所有的TaskManager。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f17-cf32-4f0c-b7c4-06f09a36058b
- slot共享另一个好处就是允许我们保存完整的作业管道。这样一来，即使某个TaskManager出现故障宕机，其他节点也可以完全不受影响，作业的任务可以继续执行
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f2b-de44-4b9a-bef3-00b9580a1ecb
- 另外，同一个任务节点的并行子任务是不能共享slot的，所以允许slot共享之后，运行作业所需的slot数量正好就是作业中所有算子并行度的最大值。这样一来，我们考虑当前集群需要配置多少slot资源时，就不需要再去详细计算一个作业总共包含多少个并行子任务了，只看最大的并行度就够了
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f43-7104-418b-a2e3-2e593ce87043
- 当然，Flink默认是允许slot共享的，如果希望某个算子对应的任务完全独占一个slot，或者只有某一部分算子共享slot，我们也可以通过设置“slot共享组”（SlotSharingGroup）手动指定：.map(word -> Tuple2.of(word, 1L)).slotSharingGroup(“1”);这样，只有属于同一个slot共享组的子任务，才会开启slot共享；不同组之间的任务是完全隔离的，必须分配到不同的slot上。在这种场景下，总共需要的slot数量，就是各个slot共享组最大并行度的总和。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f5f-ecb2-4910-8248-aed5113b5b47
- [:span]
  ls-type:: annotation
  hl-page:: 69
  id:: 624551f0-6d44-4f88-b3d9-9d73db8febc9
  hl-type:: area
  hl-stamp:: 1648710128297
- StreamExecutionEnvironment                        env                        = StreamExecutionEnvironment.getExecutionEnvironment();
  ls-type:: annotation
  hl-page:: 69
  id:: 6245531d-7ab5-43c2-8e46-cace6d0eb13c
- StreamExecutionEnvironment                     localEnv                     = StreamExecutionEnvironment.createLocalEnvironment();
  ls-type:: annotation
  hl-page:: 70
  id:: 62455327-4900-47c2-a95b-64c588a3069e
- StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment.createRemoteEnvironment("host", // JobManager主机名1234, // JobManager进程端口号"path/to/jarFile.jar"// 提交给JobManager的JAR包); 
  ls-type:: annotation
  hl-page:: 70
  id:: 62455333-4059-4d0a-a266-e4d36f31f389
- 在获取到程序执行环境后，我们还可以对执行环境进行灵活的设置。比如可以全局设置程序的并行度、禁用算子链，还可以定义程序的时间语义、配置容错机制。关于时间语义和容错机制，我们会在后续的章节介绍。
  ls-type:: annotation
  hl-page:: 70
  id:: 6245533d-b444-4af3-855e-91035b9a28e8
- bin/flink run -Dexecution.runtime-mode=BATCH
  ls-type:: annotation
  hl-page:: 71
  id:: 624553b8-d0e6-46c6-908f-3c6be96c2c9f
- [:span]
  ls-type:: annotation
  hl-page:: 72
  id:: 6245550b-ea82-43bc-ab73-c4b9d079dd19
  hl-type:: area
  hl-stamp:: 1648710923832
- [:span]
  ls-type:: annotation
  hl-page:: 82
  id:: 62466b57-e09a-407f-bdf8-4e7212545c6e
  hl-type:: area
  hl-stamp:: 1648782167373
- “富函数类”也是DataStream  API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。既然“富”，那么它一定会比常规的函数类提供更多、更丰富的功能。与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。
  ls-type:: annotation
  hl-page:: 96
  id:: 6246c794-102a-411c-8d96-1a780b226178
- [:span]
  ls-type:: annotation
  hl-page:: 106
  id:: 624d0a28-e019-4df0-b32c-11d000f59cf8
  hl-type:: area
  hl-stamp:: 1649216040884
- [:span]
  ls-type:: annotation
  hl-page:: 107
  id:: 624d0aa0-3e59-4af2-87e7-97cfae105126
  hl-type:: area
  hl-stamp:: 1649216160184
- Flink为此专门提供了一个流式文件系统的连接器：StreamingFileSink，它继承自抽象类RichSinkFunction，而且集成了Flink的检查点（checkpoint）机制，用来保证精确一次（exactly once）的一致性语义
  ls-type:: annotation
  hl-page:: 108
  id:: 624d5897-727a-4259-ba83-8dfcd325e250
- StreamingFileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded，比如Parquet）格式。这两种不同的方式都有各自的构建器（builder），调用方法也非常简单，可以直接调用StreamingFileSink的静态方法
  ls-type:: annotation
  hl-page:: 108
  id:: 624d58b3-f284-494c-b4db-60cdbbf1b3bf
- Flink官方为Kafka提供了Source和Sink的连接器，我们可以用它方便地从Kafka读写数据。如果仅仅是支持读写，那还说明不了Kafka和Flink关系的亲密；真正让它们密不可分的是，Flink与Kafka的连接器提供了端到端的精确一次（exactlyonce）语义保证，这在实际项目中是最高级别的一致性保证。关于这部分内容，我们会在后续章节做更详细的讲解
  ls-type:: annotation
  hl-page:: 110
  id:: 624d5a84-e517-4adc-82bd-457353787338
- Flink没有直接提供官方的Redis连接器，不过Bahir项目还是担任了合格的辅助角色，为我们提供了Flink-Redis的连接工具。但版本升级略显滞后，目前连接器版本为1.0，支持的Scala版本最新到2.11。由于我们的测试不涉及到Scala的相关版本变化，所以并不影响使用。在实际项目应用中，应该以匹配的组件版本运行
  ls-type:: annotation
  hl-page:: 111
  id:: 624d5dd4-ef84-4514-a23e-b3ffdff8cac0
- ElasticSearch是一个分布式的开源搜索和分析引擎，适用于所有类型的数据。ElasticSearch有着简洁的REST风格的API，以良好的分布式特性、速度和可扩展性而闻名，在大数据领域应用非常广泛。Flink为ElasticSearch专门提供了官方的Sink 连接器，Flink1.13支持当前最新版本的ElasticSearch
  ls-type:: annotation
  hl-page:: 113
  id:: 624d64b8-ea6f-4870-a0b3-edacc8bbdc83
- 关系型数据库有着非常好的结构化数据设计、方便的SQL查询，是很多企业中业务数据存储的主要形式。MySQL就是其中的典型代表。尽管在大数据处理中直接与MySQL交互的场景不多，但最终处理的计算结果是要给外部应用消费使用的，而外部应用读取的数据存储往往就是MySQL。所以我们也需要知道如何将数据输出到MySQL这样的传统数据库
  ls-type:: annotation
  hl-page:: 116
  id:: 624d64f5-9a95-43e3-80a3-e8dec01baee7
- 与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的.addSink()方法就可以自定义写入任何外部存储
  ls-type:: annotation
  hl-page:: 118
  id:: 624d6516-35c7-44f1-90f2-f292732b462b
- 在实现SinkFunction的时候，需要重写的一个关键方法invoke()，在这个方法中我们就可以实现将流里的数据发送出去的逻辑
  ls-type:: annotation
  hl-page:: 118
  id:: 624d6528-9cff-4418-bfb0-3644bff5f1a3
- 在流数据处理应用中，一个很重要、也很常见的操作就是窗口计算。所谓的“窗口”，一般就是划定的一段时间范围，也就是“时间窗”；对在这范围内的数据进行处理，就是所谓的窗口计算。所以窗口和时间往往是分不开的。接下来我们就深入了解一下Flink中的时间语义和窗口的应用
  ls-type:: annotation
  hl-page:: 120
  id:: 624d73cd-f0f4-4503-8c5b-a249320e88a2
- [:span]
  ls-type:: annotation
  hl-page:: 121
  id:: 624d73e6-ad9f-4d11-bcb7-dec87e9b12b7
  hl-type:: area
  hl-stamp:: 1649243110616
- 如图6-1所示，在事件发生之后，生成的数据被收集起来，首先进入分布式消息队列，然后被Flink系统中的Source算子读取消费，进而向下游的转换算子（窗口算子）传递，最终由窗口算子进行计算处理
  ls-type:: annotation
  hl-page:: 121
  id:: 624d7450-47f1-4794-b90b-7a420f938162
- 处理时间的概念非常简单，就是指执行处理操作的机器的系统时间
  ls-type:: annotation
  hl-page:: 122
  id:: 624d747f-09b4-467a-9960-0f4471a71d76
- 事件时间，是指每个事件在对应的设备上发生的时间，也就是数据生成的时间
  ls-type:: annotation
  hl-page:: 122
  id:: 624d7486-7d16-4c11-8bf5-36eec0a20ca0
- 在实际应用中，事件时间语义会更为常见。一般情况下，业务日志数据中都会记录数据生成的时间戳（timestamp），它就可以作为事件时间的判断基础
  ls-type:: annotation
  hl-page:: 123
  id:: 624d752b-f7b6-40ec-956c-57fe3a40198c
- 事件时间语义是以一定延迟为代价，换来了处理结果的正确性。由于网络延迟一般只有毫秒级，所以即使是事件时间语义，同样可以完成低延迟实时流处理的任务
  ls-type:: annotation
  hl-page:: 124
  id:: 624d758e-ebea-4e88-9757-486fc6217c9f
- 另外，除了事件时间和处理时间，Flink还有一个“摄入时间”（Ingestion Time）的概念，它是指数据进入Flink数据流的时间，也就是Source算子读入数据的时间。摄入时间相当于是事件时间和处理时间的一个中和，它是把Source任务的处理时间，当作了数据的产生时间添加到数据里。这样一来，水位线（watermark）也就基于这个时间直接生成，不需要单独指定了。这种时间语义可以保证比较好的正确性，同时又不会引入太大的延迟。它的具体行为跟事件时间非常像，可以当作特殊的事件时间来处理。在Flink中，由于处理时间比较简单，早期版本默认的时间语义是处理时间；而考虑到事件时间在实际应用中更为广泛，从1.12版本开始，Flink已经将事件时间作为了默认的时间语义。
  ls-type:: annotation
  hl-page:: 124
  id:: 624d75b1-badc-4aaf-8841-2cf3c0567484
- [:span]
  ls-type:: annotation
  hl-page:: 126
  id:: 624d75ec-cd06-4784-a920-40e3e39611d1
  hl-type:: area
  hl-stamp:: 1649243628159
- 所以我们应该把时钟也以数据的形式传递出去，告诉下游任务当前时间的进展；而且这个时钟的传递不会因为窗口聚合之类的运算而停滞。一种简单的想法是，在数据流中加入一个时钟标记，记录当前的事件时间；这个标记可以直接广播到下游，当下游任务收到这个标记，就可以更新自己的时钟了。由于类似于水流中用来做标志的记号，在Flink中，这种用来衡量事件时间（Event Time）进展的标记，就被称作“水位线”（Watermark）。具体实现上，水位线可以看作一条特殊的数据记录，它是插入到数据流中的一个标记点，主要内容就是一个时间戳，用来指示当前的事件时间。而它插入流中的位置，就应该是在某个数据到来之后；这样就可以从这个数据中提取时间戳，作为当前水位线的时间戳了。
  ls-type:: annotation
  hl-page:: 127
  id:: 624d7695-7a05-4437-9d37-e5daced9ea8d
- [:span]
  ls-type:: annotation
  hl-page:: 127
  id:: 624d76a2-30ff-4449-ad1a-d17f74994e5f
  hl-type:: area
  hl-stamp:: 1649243810153
- 在理想状态下，数据应该按照它们生成的先后顺序、排好队进入流中；也就是说，它们处理的过程会保持原先的顺序不变，遵守先来后到的原则。这样的话我们从每个数据中提取时间戳，就可以保证总是从小到大增长的，从而插入的水位线也会不断增长、事件时钟不断向前推进
  ls-type:: annotation
  hl-page:: 127
  id:: 624d771d-b069-49ce-a5b8-daefa46b3118
- 实际应用中，如果当前数据量非常大，可能会有很多数据的时间戳是相同的，这时每来一条数据就提取时间戳、插入水位线就做了大量的无用功。而且即使时间戳不同，同时涌来的数据时间差会非常小（比如几毫秒），往往对处理计算也没什么影响。所以为了提高效率，一般会每隔一段时间生成一个水位线，这个水位线的时间戳，就是当前最新数据的时间戳，如图6-6所示。所以这时的水位线，其实就是有序流中的一个周期性出现的时间标记
  ls-type:: annotation
  hl-page:: 127
  id:: 624d7723-e7a3-4d42-a428-0e0506554434
- [:span]
  ls-type:: annotation
  hl-page:: 128
  id:: 624d7738-58d0-4497-8523-1da0b5853af2
  hl-type:: area
  hl-stamp:: 1649243960966
- 这里需要注意的是，水位线插入的“周期”，本身也是一个时间概念。在当前事件时间语义下，假如我们设定了每隔100ms生成一次水位线，那就是要等事件时钟推进100ms才能插入；但是事件时钟本身的进展，本身就是靠水位线来表示的——现在要插入一个水位线，可前提又是水位线要向前推进100ms，这就陷入了死循环。所以对于水位线的周期性生成，周期时间是指处理时间（系统时间），而不是事件时间
  ls-type:: annotation
  hl-page:: 128
  id:: 624d7741-e155-4d0c-90e5-af1da5cdbef8
- 有序流的处理非常简单，看起来水位线也并没有起到太大的作用。但这种情况只存在于理想状态下。我们知道在分布式系统中，数据在节点间传输，会因为网络传输延迟的不确定性，导致顺序发生改变，这就是所谓的“乱序数据”
  ls-type:: annotation
  hl-page:: 128
  id:: 624d7763-2dbe-4064-9d3f-61293225b7ea
- 这里所说的“乱序”（out-of-order），是指数据的先后顺序不一致，主要就是基于数据的产生时间而言的。如图6-7所示，一个7秒时产生的数据，生成时间自然要比9秒的数据早；但是经过数据缓存和传输之后，处理任务可能先收到了9秒的数据，之后7秒的数据才姗姗来迟。这时如果我们希望插入水位线，来指示当前的事件时间进展，又该怎么做呢
  ls-type:: annotation
  hl-page:: 128
  id:: 624d776b-b031-46fa-b4ec-7b3718ac549e
- [:span]
  ls-type:: annotation
  hl-page:: 128
  id:: 624d777a-befd-4f11-b81c-1c6020008671
  hl-type:: area
  hl-stamp:: 1649244026504
- 最直观的想法自然是跟之前一样，我们还是靠数据来驱动，每来一个数据就提取它的时间戳、插入一个水位线。不过现在的情况是数据乱序，所以有可能新的时间戳比之前的还小，如果直接将这个时间的水位线再插入，我们的“时钟”就回退了——水位线就代表了时钟，时光不能倒流，所以水位线的时间戳也不能减小
  ls-type:: annotation
  hl-page:: 128
  id:: 624d77a5-9d73-4204-800c-2ef0cbb3b99f
- 解决思路也很简单：我们插入新的水位线时，要先判断一下时间戳是否比之前的大，否则就不再生成新的水位线，如图6-8所示。也就是说，只有数据的时间戳比当前时钟大，才能推动时钟前进，这时才插入水位线
  ls-type:: annotation
  hl-page:: 128
  id:: 624d77ac-653e-4ebd-9da0-657b6aac48dc
- [:span]
  ls-type:: annotation
  hl-page:: 128
  id:: 624d77bc-da3e-4c0b-86ca-86db87ff8a47
  hl-type:: area
  hl-stamp:: 1649244092583
- 如果考虑到大量数据同时到来的处理效率，我们同样可以周期性地生成水位线。这时只需要保存一下之前所有数据中的最大时间戳，需要插入水位线时，就直接以它作为时间戳生成新的水位线
  ls-type:: annotation
  hl-page:: 129
  id:: 624d77cc-d526-4354-b5e1-0f4692ad5161
- [:span]
  ls-type:: annotation
  hl-page:: 129
  id:: 624d77d7-9e4b-4fa3-a20c-7f54cfa2dab3
  hl-type:: area
  hl-stamp:: 1649244119120
- 这样做尽管可以定义出一个事件时钟，却也会带来一个非常大的问题：我们无法正确处理“迟到”的数据
  ls-type:: annotation
  hl-page:: 129
  id:: 624d782d-730c-4fed-98dc-de769f768588
- 回到上面的例子，为了让窗口能够正确收集到迟到的数据，我们也可以等上2秒；也就是用当前已有数据的最大时间戳减去2秒，就是要插入的水位线的时间戳，如图6-10所示。这样的话，9秒的数据到来之后，事件时钟不会直接推进到9秒，而是进展到了7秒；必须等到11秒的数据到来之后，事件时钟才会进展到9秒，这时迟到数据也都已收集齐，0~9秒的窗口就可以正确计算结果了
  ls-type:: annotation
  hl-page:: 129
  id:: 624d787c-4f01-4921-b832-fa8862411c02
- [:span]
  ls-type:: annotation
  hl-page:: 130
  id:: 624d78a9-8735-4d43-bf6d-346f4ee6a988
  hl-type:: area
  hl-stamp:: 1649244329103
- 水位线是Flink流处理中保证结果正确性的核心机制，它往往会跟窗口一起配合，完成对乱序数据的正确处理
  ls-type:: annotation
  hl-page:: 131
  id:: 624d79e6-9e65-4aa9-9803-f604b7d61f5f
- 在Flink的DataStream  API中 ， 有 一 个 单 独 用 于 生 成 水 位 线 的 方法：.assignTimestampsAndWatermarks()，它主要用来为流中的数据分配时间戳，并生成水位线来指示事件时间
  ls-type:: annotation
  hl-page:: 132
  id:: 624d7ad7-aa62-4e31-8123-cdaa8f544abf
- 所有的上游并行任务就像围成木桶的一块块木板，它们中最短的那一块，决定了我们桶中的水位
  ls-type:: annotation
  hl-page:: 139
  id:: 624d86d4-800d-4c72-a550-e218a8fbf472
- [:span]
  ls-type:: annotation
  hl-page:: 139
  id:: 624d86e2-4ec4-4138-8b0e-76f997bd0677
  hl-type:: area
  hl-stamp:: 1649247970080
- Flink是一种流式计算引擎，主要是来处理无界数据流的，数据源源不断、无穷无尽。想要更加方便高效地处理无界流，一种方式就是将无限数据切割成有限的“数据块”进行处理，这就是所谓的“窗口”（Window）
  ls-type:: annotation
  hl-page:: 141
  id:: 624d8926-4f07-4842-bef4-85a8e3e77edb
- 在Flink中，窗口其实并不是一个“框”，流进来的数据被框住了就只能进这一个窗口。相比之下，我们应该把窗口理解成一个“桶”，如图6-15所示。在Flink中，窗口可以把流切割成有限大小的多个“存储桶”（bucket)；每个数据都会分发到对应的桶中，当到达窗口结束时间时，就对每个桶中收集的数据进行计算处理
  ls-type:: annotation
  hl-page:: 142
  id:: 624d893e-c501-4b9b-9519-f8305ac76d58
- [:span]
  ls-type:: annotation
  hl-page:: 142
  id:: 624d894c-f5c6-4dff-abe0-11347e5de48f
  hl-type:: area
  hl-stamp:: 1649248588599
- [:span]
  ls-type:: annotation
  hl-page:: 143
  id:: 624d8963-e525-484a-b9ce-8b2ca2d13bfc
  hl-type:: area
  hl-stamp:: 1649248611224
- 时间窗口（Time Window）
  ls-type:: annotation
  hl-page:: 144
  id:: 624d89c3-e8b3-42bf-9d43-f3303f46201d
- 计数窗口（Count Window）
  ls-type:: annotation
  hl-page:: 144
  id:: 624d89cc-a708-4f42-bf79-ba086afc0fd4
- 滚动窗口（Tumbling Windows）
  ls-type:: annotation
  hl-page:: 145
  id:: 624d89d5-8af4-47f9-b226-54dfaaef6ba3
- 滑动窗口（Sliding Windows）
  ls-type:: annotation
  hl-page:: 145
  id:: 624d89dd-a838-46bd-992e-cf0c2c902035
- 会话窗口（Session Windows）
  ls-type:: annotation
  hl-page:: 146
  id:: 624d89e8-74c3-4733-a361-05b2faf363de
- 全局窗口（Global Windows）
  ls-type:: annotation
  hl-page:: 147
  id:: 624d89f8-c4ae-4c95-ab8d-d33a24116fda
- [:span]
  ls-type:: annotation
  hl-page:: 148
  id:: 624d8cf7-33fa-489f-ba95-0201b2d026ee
  hl-type:: area
  hl-stamp:: 1649249527680
- [:span]
  ls-type:: annotation
  hl-page:: 149
  id:: 624d8d63-06b8-48a1-b56a-f76bc202904f
  hl-type:: area
  hl-stamp:: 1649249635320
- 窗口分配器（Window Assigners）
  ls-type:: annotation
  hl-page:: 149
  id:: 624d8f14-011b-4ccf-8b9d-44563aeca4db
- 窗口函数（Window Functions）
  ls-type:: annotation
  hl-page:: 152
  id:: 624d8f27-39b2-4e3b-8e81-3a82de5de67f
- [:span]
  ls-type:: annotation
  hl-page:: 152
  id:: 624d8f90-7c29-4740-ab8c-e6d989e54422
  hl-type:: area
  hl-stamp:: 1649250192559
- 增量聚合函数（incremental aggregation functions）
  ls-type:: annotation
  hl-page:: 153
  id:: 624d8f9f-0e0d-437d-9d91-2965fb9e9fe1
- 归约函数（ReduceFunction）
  ls-type:: annotation
  hl-page:: 153
  id:: 624d8fa9-5743-4779-952d-3c607b7219a9
- 聚合函数（AggregateFunction）
  ls-type:: annotation
  hl-page:: 155
  id:: 624d8fb1-7a06-4197-9240-7f339c3d4783
- 全窗口函数（full window functions）
  ls-type:: annotation
  hl-page:: 159
  id:: 624d8fc0-a0ff-40cb-bc20-b3d9ef6193e6
- 窗口函数（WindowFunction）
  ls-type:: annotation
  hl-page:: 159
  id:: 624d8fc8-f423-41d1-aa61-12dc4b2ec46e
- 处理窗口函数（ProcessWindowFunction）
  ls-type:: annotation
  hl-page:: 159
  id:: 624d8fcf-a24f-4d44-9e35-053e43ae793e
- 增量聚合和全窗口函数的结合使用
  ls-type:: annotation
  hl-page:: 162
  id:: 624e8adc-14d1-453b-856c-0f6f16d726c4
- 触发器（Trigger）
  ls-type:: annotation
  hl-page:: 169
  id:: 624e8b33-a97d-4167-a62f-4895d7ab1e8f
- 移除器（Evictor）
  ls-type:: annotation
  hl-page:: 173
  id:: 624e8fcb-e66d-4992-97e7-a504d42d9b43
- 允许延迟（Allowed Lateness）
  ls-type:: annotation
  hl-page:: 173
  id:: 624e8fda-742e-4ee0-a039-7b17e245f166
- 将迟到的数据放入侧输出流
  ls-type:: annotation
  hl-page:: 174
  id:: 624e9024-9c7e-49b4-a7dd-3a8c98f336e0
- [:span]
  ls-type:: annotation
  hl-page:: 183
  id:: 624f9fec-b367-4274-817e-1efe5ba2337f
  hl-type:: area
  hl-stamp:: 1649385452726
- 处理函数提供了一个“定时服务”（TimerService），我们可以通过它访问流中的事件（event）、时间戳（timestamp）、水位线（watermark），甚至可以注册“定时事件”。而且处理函数继承了AbstractRichFunction抽象类，所以拥有富函数类的所有特性，同样可以访问状态（state）和其他运行时信息。此外，处理函数还可以直接将数据输出到侧输出流（sideoutput）中。所以，处理函数是最为灵活的处理方法，可以实现各种自定义的业务逻辑；同时也是整个DataStreamAPI的底层基础
  ls-type:: annotation
  hl-page:: 184
  id:: 624fa609-e298-4607-9209-e15ad163052f
- 处理函数的使用与基本的转换操作类似，只需要直接基于DataStream调用.process()方法就可以了
  ls-type:: annotation
  hl-page:: 184
  id:: 624fa641-8b3e-416d-87a4-f854f536d145
- ProcessFunction解析
  ls-type:: annotation
  hl-page:: 185
  id:: 624fcaec-0a62-45dc-8ec7-6fcb18040cff
- 处理函数的分类
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcaf9-0fe7-4dbd-8d73-4d9d731f414a
- Flink提供了8个不同的处理函数
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb07-91b9-4613-b348-4f3549e1dee4
- ProcessFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb0f-820a-4cd0-b4ae-0ca7fdbb25ba
- KeyedProcessFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb15-d9f7-4612-9fc3-34e3cb8874dd
- ProcessWindowFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb1b-7a75-42d0-93a0-8dbf483345d9
- ProcessAllWindowFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb20-1768-44ca-8e12-b90ab03f6b1b
- CoProcessFunction
  ls-type:: annotation
  hl-page:: 187
  id:: 624fcb29-5775-4665-97c8-2a3d59005df8
- ProcessJoinFunction
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcb2f-e54f-4ee5-a617-9b3de45dcdad
- BroadcastProcessFunction
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcb37-9ea0-4844-bc5b-892ba23266cc
- KeyedBroadcastProcessFunction
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcb3d-9372-443e-86f1-19c207a2240e
- 按键分区处理函数（KeyedProcessFunction）
  ls-type:: annotation
  hl-page:: 188
  id:: 624fcdb1-350a-489a-9aec-9625f4472497
- [:span]
  ls-type:: annotation
  hl-page:: 210
  id:: 624ffdf8-0638-43ce-ae26-a770e8e19bed
  hl-type:: area
  hl-stamp:: 1649409528679