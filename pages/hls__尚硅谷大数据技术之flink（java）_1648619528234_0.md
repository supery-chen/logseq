- 这里需要提到Flink中的几个关键组件：客户端（Client）、作业管理器（JobManager）和任务管理器（TaskManager）
  ls-type:: annotation
  hl-page:: 28
  id:: 62440a36-c97d-4cb0-939a-621b0e56e98b
- [:span]
  ls-type:: annotation
  hl-page:: 29
  id:: 62440a74-bd5d-41e4-b278-4d1f25aaba68
  hl-type:: area
  hl-stamp:: 1648626292381
- 会话模式比较适合于单个规模小、执行时间短的大量作业
  ls-type:: annotation
  hl-page:: 38
  id:: 62450ce5-4bd3-430d-ad09-3c77d87ceace
- 单作业模式在生产环境运行更加稳定，所以是实际应用的首选模式
  ls-type:: annotation
  hl-page:: 38
  id:: 62450cfa-2832-4b40-b6f9-7b46e358410e
- 我们需要为每一个提交的应用单独启动一个JobManager，也就是创建一个集群。这个JobManager只为执行这一个应用而存在，执行结束之后JobManager也就关闭了，这就是所谓的应用模式
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d13-0ed7-4469-962b-e908d22704a6
- 在会话模式下，集群的生命周期独立于集群上运行的任何作业的生命周期，并且提交的所有作业共享资源。而单作业模式为每个提交的作业创建一个集群，带来了更好的资源隔离，这时集群的生命周期与作业的生命周期绑定。最后，应用模式为每个应用程序创建一个会话集群，在JobManager上直接调用应用程序的main()方法
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d33-59e4-48c0-ad47-02c1bc2cd5f3
- YARN上部署的过程是：客户端把Flink应用提交给Yarn的ResourceManager, Yarn的ResourceManager会向Yarn的NodeManager申请容器。在这些容器上，Flink会部署JobManager和TaskManager的实例，从而启动集群。Flink会根据运行在JobManger上的作业所需要的Slot数量动态分配TaskManager资源。
  ls-type:: annotation
  hl-page:: 42
  id:: 62450dec-7154-4f5d-819e-fc4150cff13e
- [:span]
  ls-type:: annotation
  hl-page:: 49
  id:: 62451f28-540a-4c62-abfe-46958ef9aef6
  hl-type:: area
  hl-stamp:: 1648697128409
- Flink的运行时架构中，最重要的就是两大组件：作业管理器（JobManger）和任务管理器（TaskManager）。对于一个提交执行的作业，JobManager是真正意义上的“管理者”（Master），负责管理调度，所以在不考虑高可用的情况下只能有一个；而TaskManager是“工作者”（Worker、Slave），负责执行任务处理数据，所以可以有一个或多个。Flink的作业提交和任务处理时的系统如图4-1所示。
  ls-type:: annotation
  hl-page:: 48
  id:: 62451f57-78fd-4be4-ad93-a47a58f42523
- [:span]
  ls-type:: annotation
  hl-page:: 51
  id:: 62453fc2-a342-43cb-8e2c-678f7917fb1d
  hl-type:: area
  hl-stamp:: 1648705474055
- [:span]
  ls-type:: annotation
  hl-page:: 52
  id:: 62454063-0020-4aa4-b678-18e16e071e4f
  hl-type:: area
  hl-stamp:: 1648705635790
- [:span]
  ls-type:: annotation
  hl-page:: 53
  id:: 62454115-6eba-4154-ab1d-e057d767c4a2
  hl-type:: area
  hl-stamp:: 1648705813730
- [:span]
  ls-type:: annotation
  hl-page:: 54
  id:: 62454135-1954-4edb-99bf-2f6d9975f66e
  hl-type:: area
  hl-stamp:: 1648705845181
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 624541f2-189f-4995-a375-3ef37f35add8
  hl-type:: area
  hl-stamp:: 1648706034535
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 6245466b-87c3-47f2-b8e0-eb30d8b2cfa7
  hl-type:: area
  hl-stamp:: 1648707179638
- [:span]
  ls-type:: annotation
  hl-page:: 57
  id:: 62454701-8930-4021-934b-388c85a330e5
  hl-type:: area
  hl-stamp:: 1648707329143
- 一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。这样，包含并行子任务的数据流，就是并行数据流，它需要多个分区（stream  partition）来分配并行任务。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。如图4-8所示，当前数据流中有source、map、window、sink四个算子，除最后sink，其他算子的并行度都为2。整个程序包含了7个子任务，至少需要2个分区来并行执行。我们可以说，这段流处理程序的并行度就是2。
  ls-type:: annotation
  hl-page:: 57
  id:: 6245471b-13ef-4cfb-975d-69af821a09d0
- [:span]
  ls-type:: annotation
  hl-page:: 61
  id:: 62454a8d-db87-42a7-838d-611c206f0a5e
  hl-type:: area
  hl-stamp:: 1648708237078
- [:span]
  ls-type:: annotation
  hl-page:: 63
  id:: 62454e39-97d3-4303-a24a-a1467fc124fa
  hl-type:: area
  hl-stamp:: 1648709177499
- 我们可以通过集群的配置文件来设定TaskManager的slot数量：taskmanager.numberOfTaskSlots: 8通过调整slot的数量，我们就可以控制子任务之间的隔离级别。具体来说，如果一个TaskManager只有一个slot，那将意味着每个任务都会运行在独立的JVM中（当然，该JVM可能是通过一个特定的容器启动的）；而一个TaskManager设置多个slot则意味着多个子任务可以共享同一个JVM。它们的区别在于：前者任务之间完全独立运行，隔离级别更高、彼此间的影响可以降到最小；而后者在同一个JVM进程中运行的任务，将共享TCP连接和心跳消息，也可能共享数据集和数据结构，这就减少了每个任务的运行开销，在降低隔离级别的同时提升了性能。需要注意的是，slot目前仅仅用来隔离内存，不会涉及CPU的隔离。在具体应用时，可以将slot数量配置为机器的CPU核心数，尽量避免不同任务之间对CPU的竞争。这也是开发环境默认并行度设为机器CPU数量的原因。
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e59-5ef5-47ad-85b9-66b9677fa165
- [:span]
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e82-ff8f-4b89-b726-614cb95daff5
  hl-type:: area
  hl-stamp:: 1648709252945
- 默认情况下，Flink是允许子任务共享slot的
  ls-type:: annotation
  hl-page:: 65
  id:: 62454e91-b72e-43b4-86a2-5c5565148a9e
- 只要属于同一个作业，那么对于不同任务节点的并行子任务，就可以放到同一个slot上执行。所以对于第一个任务节点source→map，它的6个并行子任务必须分到不同的slot上（如果在同一slot就没法数据并行了），而第二个任务节点keyBy/window/apply的并行子任务却可以和第一个任务节点共享slot。于是最终结果就变成了：每个任务节点的并行子任务一字排开，占据不同的slot；而不同的任务节点的子任务可以共享slot。一个slot中，可以将程序处理的所有任务都放在这里执行，我们把它叫作保存了整个作业的运行管道（pipeline）。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454ee2-c050-42d0-a67a-8d1e48e7e94f