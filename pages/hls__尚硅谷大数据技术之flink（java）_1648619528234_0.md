- 这里需要提到Flink中的几个关键组件：客户端（Client）、作业管理器（JobManager）和任务管理器（TaskManager）
  ls-type:: annotation
  hl-page:: 28
  id:: 62440a36-c97d-4cb0-939a-621b0e56e98b
- [:span]
  ls-type:: annotation
  hl-page:: 29
  id:: 62440a74-bd5d-41e4-b278-4d1f25aaba68
  hl-type:: area
  hl-stamp:: 1648626292381
- 会话模式比较适合于单个规模小、执行时间短的大量作业
  ls-type:: annotation
  hl-page:: 38
  id:: 62450ce5-4bd3-430d-ad09-3c77d87ceace
- 单作业模式在生产环境运行更加稳定，所以是实际应用的首选模式
  ls-type:: annotation
  hl-page:: 38
  id:: 62450cfa-2832-4b40-b6f9-7b46e358410e
- 我们需要为每一个提交的应用单独启动一个JobManager，也就是创建一个集群。这个JobManager只为执行这一个应用而存在，执行结束之后JobManager也就关闭了，这就是所谓的应用模式
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d13-0ed7-4469-962b-e908d22704a6
- 在会话模式下，集群的生命周期独立于集群上运行的任何作业的生命周期，并且提交的所有作业共享资源。而单作业模式为每个提交的作业创建一个集群，带来了更好的资源隔离，这时集群的生命周期与作业的生命周期绑定。最后，应用模式为每个应用程序创建一个会话集群，在JobManager上直接调用应用程序的main()方法
  ls-type:: annotation
  hl-page:: 39
  id:: 62450d33-59e4-48c0-ad47-02c1bc2cd5f3
- YARN上部署的过程是：客户端把Flink应用提交给Yarn的ResourceManager, Yarn的ResourceManager会向Yarn的NodeManager申请容器。在这些容器上，Flink会部署JobManager和TaskManager的实例，从而启动集群。Flink会根据运行在JobManger上的作业所需要的Slot数量动态分配TaskManager资源。
  ls-type:: annotation
  hl-page:: 42
  id:: 62450dec-7154-4f5d-819e-fc4150cff13e
- [:span]
  ls-type:: annotation
  hl-page:: 49
  id:: 62451f28-540a-4c62-abfe-46958ef9aef6
  hl-type:: area
  hl-stamp:: 1648697128409
- Flink的运行时架构中，最重要的就是两大组件：作业管理器（JobManger）和任务管理器（TaskManager）。对于一个提交执行的作业，JobManager是真正意义上的“管理者”（Master），负责管理调度，所以在不考虑高可用的情况下只能有一个；而TaskManager是“工作者”（Worker、Slave），负责执行任务处理数据，所以可以有一个或多个。Flink的作业提交和任务处理时的系统如图4-1所示。
  ls-type:: annotation
  hl-page:: 48
  id:: 62451f57-78fd-4be4-ad93-a47a58f42523
- [:span]
  ls-type:: annotation
  hl-page:: 51
  id:: 62453fc2-a342-43cb-8e2c-678f7917fb1d
  hl-type:: area
  hl-stamp:: 1648705474055
- [:span]
  ls-type:: annotation
  hl-page:: 52
  id:: 62454063-0020-4aa4-b678-18e16e071e4f
  hl-type:: area
  hl-stamp:: 1648705635790
- [:span]
  ls-type:: annotation
  hl-page:: 53
  id:: 62454115-6eba-4154-ab1d-e057d767c4a2
  hl-type:: area
  hl-stamp:: 1648705813730
- [:span]
  ls-type:: annotation
  hl-page:: 54
  id:: 62454135-1954-4edb-99bf-2f6d9975f66e
  hl-type:: area
  hl-stamp:: 1648705845181
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 624541f2-189f-4995-a375-3ef37f35add8
  hl-type:: area
  hl-stamp:: 1648706034535
- [:span]
  ls-type:: annotation
  hl-page:: 55
  id:: 6245466b-87c3-47f2-b8e0-eb30d8b2cfa7
  hl-type:: area
  hl-stamp:: 1648707179638
- [:span]
  ls-type:: annotation
  hl-page:: 57
  id:: 62454701-8930-4021-934b-388c85a330e5
  hl-type:: area
  hl-stamp:: 1648707329143
- 一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。这样，包含并行子任务的数据流，就是并行数据流，它需要多个分区（stream  partition）来分配并行任务。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。如图4-8所示，当前数据流中有source、map、window、sink四个算子，除最后sink，其他算子的并行度都为2。整个程序包含了7个子任务，至少需要2个分区来并行执行。我们可以说，这段流处理程序的并行度就是2。
  ls-type:: annotation
  hl-page:: 57
  id:: 6245471b-13ef-4cfb-975d-69af821a09d0
- [:span]
  ls-type:: annotation
  hl-page:: 61
  id:: 62454a8d-db87-42a7-838d-611c206f0a5e
  hl-type:: area
  hl-stamp:: 1648708237078
- [:span]
  ls-type:: annotation
  hl-page:: 63
  id:: 62454e39-97d3-4303-a24a-a1467fc124fa
  hl-type:: area
  hl-stamp:: 1648709177499
- 我们可以通过集群的配置文件来设定TaskManager的slot数量：taskmanager.numberOfTaskSlots: 8通过调整slot的数量，我们就可以控制子任务之间的隔离级别。具体来说，如果一个TaskManager只有一个slot，那将意味着每个任务都会运行在独立的JVM中（当然，该JVM可能是通过一个特定的容器启动的）；而一个TaskManager设置多个slot则意味着多个子任务可以共享同一个JVM。它们的区别在于：前者任务之间完全独立运行，隔离级别更高、彼此间的影响可以降到最小；而后者在同一个JVM进程中运行的任务，将共享TCP连接和心跳消息，也可能共享数据集和数据结构，这就减少了每个任务的运行开销，在降低隔离级别的同时提升了性能。需要注意的是，slot目前仅仅用来隔离内存，不会涉及CPU的隔离。在具体应用时，可以将slot数量配置为机器的CPU核心数，尽量避免不同任务之间对CPU的竞争。这也是开发环境默认并行度设为机器CPU数量的原因。
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e59-5ef5-47ad-85b9-66b9677fa165
- [:span]
  ls-type:: annotation
  hl-page:: 64
  id:: 62454e82-ff8f-4b89-b726-614cb95daff5
  hl-type:: area
  hl-stamp:: 1648709252945
- 默认情况下，Flink是允许子任务共享slot的
  ls-type:: annotation
  hl-page:: 65
  id:: 62454e91-b72e-43b4-86a2-5c5565148a9e
- 只要属于同一个作业，那么对于不同任务节点的并行子任务，就可以放到同一个slot上执行。所以对于第一个任务节点source→map，它的6个并行子任务必须分到不同的slot上（如果在同一slot就没法数据并行了），而第二个任务节点keyBy/window/apply的并行子任务却可以和第一个任务节点共享slot。于是最终结果就变成了：每个任务节点的并行子任务一字排开，占据不同的slot；而不同的任务节点的子任务可以共享slot。一个slot中，可以将程序处理的所有任务都放在这里执行，我们把它叫作保存了整个作业的运行管道（pipeline）。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454ee2-c050-42d0-a67a-8d1e48e7e94f
- 当我们将资源密集型和非密集型的任务同时放到一个slot中，它们就可以自行分配对资源占用的比例，从而保证最重的活平均分配给所有的TaskManager。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f17-cf32-4f0c-b7c4-06f09a36058b
- slot共享另一个好处就是允许我们保存完整的作业管道。这样一来，即使某个TaskManager出现故障宕机，其他节点也可以完全不受影响，作业的任务可以继续执行
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f2b-de44-4b9a-bef3-00b9580a1ecb
- 另外，同一个任务节点的并行子任务是不能共享slot的，所以允许slot共享之后，运行作业所需的slot数量正好就是作业中所有算子并行度的最大值。这样一来，我们考虑当前集群需要配置多少slot资源时，就不需要再去详细计算一个作业总共包含多少个并行子任务了，只看最大的并行度就够了
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f43-7104-418b-a2e3-2e593ce87043
- 当然，Flink默认是允许slot共享的，如果希望某个算子对应的任务完全独占一个slot，或者只有某一部分算子共享slot，我们也可以通过设置“slot共享组”（SlotSharingGroup）手动指定：.map(word -> Tuple2.of(word, 1L)).slotSharingGroup(“1”);这样，只有属于同一个slot共享组的子任务，才会开启slot共享；不同组之间的任务是完全隔离的，必须分配到不同的slot上。在这种场景下，总共需要的slot数量，就是各个slot共享组最大并行度的总和。
  ls-type:: annotation
  hl-page:: 65
  id:: 62454f5f-ecb2-4910-8248-aed5113b5b47
- [:span]
  ls-type:: annotation
  hl-page:: 69
  id:: 624551f0-6d44-4f88-b3d9-9d73db8febc9
  hl-type:: area
  hl-stamp:: 1648710128297
- StreamExecutionEnvironment                        env                        = StreamExecutionEnvironment.getExecutionEnvironment();
  ls-type:: annotation
  hl-page:: 69
  id:: 6245531d-7ab5-43c2-8e46-cace6d0eb13c
- StreamExecutionEnvironment                     localEnv                     = StreamExecutionEnvironment.createLocalEnvironment();
  ls-type:: annotation
  hl-page:: 70
  id:: 62455327-4900-47c2-a95b-64c588a3069e
- StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment.createRemoteEnvironment("host", // JobManager主机名1234, // JobManager进程端口号"path/to/jarFile.jar"// 提交给JobManager的JAR包); 
  ls-type:: annotation
  hl-page:: 70
  id:: 62455333-4059-4d0a-a266-e4d36f31f389
- 在获取到程序执行环境后，我们还可以对执行环境进行灵活的设置。比如可以全局设置程序的并行度、禁用算子链，还可以定义程序的时间语义、配置容错机制。关于时间语义和容错机制，我们会在后续的章节介绍。
  ls-type:: annotation
  hl-page:: 70
  id:: 6245533d-b444-4af3-855e-91035b9a28e8
- bin/flink run -Dexecution.runtime-mode=BATCH
  ls-type:: annotation
  hl-page:: 71
  id:: 624553b8-d0e6-46c6-908f-3c6be96c2c9f
- [:span]
  ls-type:: annotation
  hl-page:: 72
  id:: 6245550b-ea82-43bc-ab73-c4b9d079dd19
  hl-type:: area
  hl-stamp:: 1648710923832
- [:span]
  ls-type:: annotation
  hl-page:: 82
  id:: 62466b57-e09a-407f-bdf8-4e7212545c6e
  hl-type:: area
  hl-stamp:: 1648782167373
- “富函数类”也是DataStream  API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。既然“富”，那么它一定会比常规的函数类提供更多、更丰富的功能。与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。
  ls-type:: annotation
  hl-page:: 96
  id:: 6246c794-102a-411c-8d96-1a780b226178
- [:span]
  ls-type:: annotation
  hl-page:: 106
  id:: 624d0a28-e019-4df0-b32c-11d000f59cf8
  hl-type:: area
  hl-stamp:: 1649216040884
- [:span]
  ls-type:: annotation
  hl-page:: 107
  id:: 624d0aa0-3e59-4af2-87e7-97cfae105126
  hl-type:: area
  hl-stamp:: 1649216160184
- Flink为此专门提供了一个流式文件系统的连接器：StreamingFileSink，它继承自抽象类RichSinkFunction，而且集成了Flink的检查点（checkpoint）机制，用来保证精确一次（exactly once）的一致性语义
  ls-type:: annotation
  hl-page:: 108
  id:: 624d5897-727a-4259-ba83-8dfcd325e250
- StreamingFileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded，比如Parquet）格式。这两种不同的方式都有各自的构建器（builder），调用方法也非常简单，可以直接调用StreamingFileSink的静态方法
  ls-type:: annotation
  hl-page:: 108
  id:: 624d58b3-f284-494c-b4db-60cdbbf1b3bf
- Flink官方为Kafka提供了Source和Sink的连接器，我们可以用它方便地从Kafka读写数据。如果仅仅是支持读写，那还说明不了Kafka和Flink关系的亲密；真正让它们密不可分的是，Flink与Kafka的连接器提供了端到端的精确一次（exactlyonce）语义保证，这在实际项目中是最高级别的一致性保证。关于这部分内容，我们会在后续章节做更详细的讲解
  ls-type:: annotation
  hl-page:: 110
  id:: 624d5a84-e517-4adc-82bd-457353787338
- Flink没有直接提供官方的Redis连接器，不过Bahir项目还是担任了合格的辅助角色，为我们提供了Flink-Redis的连接工具。但版本升级略显滞后，目前连接器版本为1.0，支持的Scala版本最新到2.11。由于我们的测试不涉及到Scala的相关版本变化，所以并不影响使用。在实际项目应用中，应该以匹配的组件版本运行
  ls-type:: annotation
  hl-page:: 111
  id:: 624d5dd4-ef84-4514-a23e-b3ffdff8cac0
- ElasticSearch是一个分布式的开源搜索和分析引擎，适用于所有类型的数据。ElasticSearch有着简洁的REST风格的API，以良好的分布式特性、速度和可扩展性而闻名，在大数据领域应用非常广泛。Flink为ElasticSearch专门提供了官方的Sink 连接器，Flink1.13支持当前最新版本的ElasticSearch
  ls-type:: annotation
  hl-page:: 113
  id:: 624d64b8-ea6f-4870-a0b3-edacc8bbdc83
- 关系型数据库有着非常好的结构化数据设计、方便的SQL查询，是很多企业中业务数据存储的主要形式。MySQL就是其中的典型代表。尽管在大数据处理中直接与MySQL交互的场景不多，但最终处理的计算结果是要给外部应用消费使用的，而外部应用读取的数据存储往往就是MySQL。所以我们也需要知道如何将数据输出到MySQL这样的传统数据库
  ls-type:: annotation
  hl-page:: 116
  id:: 624d64f5-9a95-43e3-80a3-e8dec01baee7
- 与Source类似，Flink为我们提供了通用的SinkFunction接口和对应的RichSinkDunction抽象类，只要实现它，通过简单地调用DataStream的.addSink()方法就可以自定义写入任何外部存储
  ls-type:: annotation
  hl-page:: 118
  id:: 624d6516-35c7-44f1-90f2-f292732b462b
- 在实现SinkFunction的时候，需要重写的一个关键方法invoke()，在这个方法中我们就可以实现将流里的数据发送出去的逻辑
  ls-type:: annotation
  hl-page:: 118
  id:: 624d6528-9cff-4418-bfb0-3644bff5f1a3